{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from http import HTTPStatus\n",
    "from dashscope import Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_ai(question, session_id=None):\n",
    "    try:\n",
    "        response = Application.call(\n",
    "            api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "            app_id='2c67f3e7920a40c1a6a315053a819c9f',\n",
    "            prompt=question,\n",
    "            session_id=session_id,\n",
    "            stream=False,\n",
    "            has_thoughts = True,\n",
    "            rag_options={\n",
    "                \"pipeline_ids\": [\"gqhpyjb6l1\"],  # 替换为实际的知识库ID,逗号隔开多个\n",
    "            },\n",
    "            enable_system_time = True\n",
    "        )\n",
    "\n",
    "        if response.status_code != HTTPStatus.OK:\n",
    "            return None, None\n",
    "\n",
    "        # 提取有用信息，包括可能为空的 thoughts 和 doc_references\n",
    "        result = {\n",
    "            'text': response.output.text,  # AI的回复\n",
    "            'session_id': response.output.session_id,  # 会话ID\n",
    "            'request_id': response.request_id,  # 请求ID\n",
    "            'model': response.usage.models[0].model_id,  # 使用的模型\n",
    "            'input_tokens': response.usage.models[0].input_tokens,  # 输入token数\n",
    "            'output_tokens': response.usage.models[0].output_tokens,  # 输出token数\n",
    "            'finish_reason': response.output.finish_reason,  # 完成原因\n",
    "            'thoughts': response.output.thoughts,  # AI的思考过程\n",
    "            'doc_references': response.output.doc_references  # 文档引用\n",
    "        }\n",
    "        \n",
    "        return result, response.output.session_id\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'发生错误: {str(e)}')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI回复: 这节课的内容主要是关于提示工程（Prompt Engineering）的五大核心技巧，包括结构化提示、少样本学习、思维链提示、ReAct提示和提示迭代<ref>[4]</ref>。课程会详细介绍每个技巧的定义、应用场景以及如何有效地使用这些技巧来优化与AI的交互过程。此外，还会通过具体的案例分析和实操练习，帮助学生掌握如何编写高质量的提示词，从而提升AI输出的质量和准确性<ref>[3]</ref>。\n",
      "\n",
      "为了更好地理解这些内容，我们可以先从一个具体的技巧开始讨论。比如，你对哪一个技巧最感兴趣，或者你觉得哪一个技巧在你的学习中最有用呢？这样我们可以更有针对性地探讨和实践。\n",
      "会话ID: abd29dca28ed4c8a9e1ca9111fd7908e\n",
      "请求ID: f4f699fc-63b8-981e-86d8-498618d75c5a\n",
      "使用模型: qwen-max-latest\n",
      "输入token数: 14274\n",
      "输出token数: 148\n",
      "完成原因: stop\n",
      "思考过程: [ApplicationThought(thought=None, action_type='agentRag', response=None, action_name='知识检索', action='rag', action_input_stream='{}', action_input=None, observation='[{\"content\":\"【文档名】:第7周-提示词工程模块拓展资源内容\\\\n【标题】:第7周-提示词工程模块拓展资源内容\\\\npipeline_name:AI基础课知识库\\\\n【正文】:第7周-提示词工程模块拓展资源内容\\\\n\\\\n课后阅读拓展资源:\\\\n\\\\n1.阿里云百炼大模型服务平台的提示工程指南文档:\\\\n\\\\n·文生文:\\\\n\\\\nhttps://help.aliyun.com/zh/model-studio/use-cases/prompt-engineering-guide?spm=5176.21213303.J_v8LsmxMG6alneH-\\\\n\\\\nO7TCPa.9.1a172f3dtGycJd&scm=20140722.S_help@@文档@@2735998._.ID_help@@文档@@2735998-RL_提示词-\\\\n\\\\nLOC_2024SPAllResult-OR_ser-PAR1_2150442e17478689122497808eceab-V_4-RE_new5-P0_2-P1_0\\\\n\\\\n·文生图:\\\\n\\\\nhttps://help.aliyun.com/zh/model-studio/use-cases/text-to-image-prompt\\\\n\\\\n·文生视频:\\\\n\\\\nhttps://help.aliyun.com/zh/model-studio/text-to-video-prompt?spm=a2c4g.11186623.0.i2\\\\n\\\\n2. Claude 3.7核心提示词曝光|最懂提示词的大模型公司,现在怎么写 Prompt?:https://sspai.com/post/96734\\\\n\\\\n3.提示词工程的问题视角-讨论了提示词工程在大语言模型交互中的重要性,并强调明确描述问题对于获得精准回答至关重要:\\\\n\\\\nhttps://sspai.com/post/85484\\\\n \\\\n\\\\n\",\"dataId\":\"file_30a85c350dc94d919d5ff0e448f7b283_12039021\",\"dataName\":\"第7周-提示词工程模块拓展资源内容\",\"display\":true,\"enableSpecifiedModel\":false,\"id\":\"gqhpyjb6l1_file_30a85c350dc94d919d5ff0e448f7b283_12039021\",\"rankWeight\":1.0,\"referenceIndex\":1,\"rejectStatus\":false,\"score\":0.99,\"scoreWithWeight\":0.99,\"title\":\"第7周-提示词工程模块拓展资源内容\",\"webSearch\":false},{\"content\":\"【文档名】:AI课程大纲\\\\n【标题】:AI课程大纲\\\\npipeline_name:AI基础课知识库\\\\n【正文】:课程大纲\\\\n\\\\n本课程《人工智能基础导论:AI跨学科工具化思维、伦理设计与应用创想》\\\\n\\\\n专为人文社科类非计算机专业本科生设计,旨在构建\\\\\"认知一应用一伦理一创新\\\\\"四位一体的能力框架。通过系统学习人工智能的基础知识、技术演进与实际应用场景,学生将掌握AI的基本概念与发展脉络,能够在无代码或低代码平台上独立完成常见任务的操作与调优,形成负责任的技术使用意识,并具备跨学科创新思维和迁移能力。\\\\n\\\\n课程融合了零基础教学中工具分类的逻辑思路与技术发展的演进路径,使内容体系更加平衡且易于接受。整个教学过程强调工具操作与伦理思辨的结合,采用\\\\\"知识讲解→案例分析→工具实践→测验反馈\\\\\"的闭环流程,帮助学生在动手实践中深化理解。\\\\n\\\\n每一堂课安排约15分钟的知识点讲解,随后是10至15分钟的案例解析、10分钟的实操环节以及最后5分钟的小测验与讨论,确保学生能够\\\\\"看得懂、学得会、用得出\\\\\"。\\\\n\\\\n所有教学实践均基于网页端可访问的中文无代码/低代码平台,无需编程基础即可上手主流AI工具。课程秉持\\\\\"课堂即实验室\\\\\"的理念,将理论与实践紧密结合,使学生在完成典型任务的过程中逐步建立起对人工智能的全面认知。\\\\n\\\\n课程总时长为14周,采用螺旋递进与模块化组合的教学结构,强化\\\\\"做中学\\\\\"的理念。前两周用于介绍人工智能的起源、发展简史与核心概念;接下来三周围绕机器学习与深度学习展开基础知识的学习与实践体验;随后六周聚焦大语言模型的应用与提示词工程,涵盖RAG工作流与智能体构建等内容;再安排一周时间深入探讨人工智能的社会影响与伦理问题;最后两周用于跨学科项目的构思、实施与成果展示,形成完整的学习闭环。\\\\n\\\\n具体章节安排如下:第一周引导学生了解人工智能的基本定义、发展历程及社会影响,明确课程目标与学习计划;第二周介绍基于规则与基于学习的AI差异,讲解机器学习的基本流程与算法类型;第三周开始接触AutoML平台,训练简单的图像分类模型,初步建立\\\\\"无需编程也能训练模型\\\\\"的认知;第四周讲解神经网络的基本原理与深度学习的优势,第五周进入计算机视觉的实际应用,第六周则转向自然语言处理与大语言模型的使用体验;第七周重点在于提示词工程的设计与实践,第八周介绍知识表示与RAG流程,第九周学习复杂智能体的构建方法;第十与第十一周分别以艺术创意与理科商科为背景,探索AI在不同领域的应用;第十二周深入讨论AI带来的社会影响与伦理挑战;第十三周指导学生完成个性化跨学科小项目;最后一周进行项目展示与课程总结,学生以小组形式汇报成果,教师与同学共同参与点评,实现即时反馈与经验分享。\\\\n\\\\n为了增强课程的适用性与延展性,课程特别设计了跨学科项目库,提供多个领域中的AI应用模板,如文学中的文本情感分析、历史中的文献智能处理、法学中的法律文书生成、艺术学中的智能创作、医学中的辅助诊断、经管中的决策支持等,帮助学生结合自身专业背景开展创新实践。同时,教学内容分为基础模块、专业模块与拓展模块,满足不同专业学生的个性化需求。\\\\n \\\\n在实践环境方面,课程依托多个中文AI平台,包括模型训练平台、视觉拖拽工具、多模态生成器以及RAG与智能体构建平台,确保学生能够在一个统一、易用的环境中完成各类任务。教学过程中还将提供账号批量申请、算力保障、数据合规管理等支持措施,配合AI助教团队协助答疑与作业批改,提升教学效率与学习体验。\\\\n\\\\n课程评估体系注重过程性与综合表现相结合,包含课堂互动与随堂测验、每周实操日志、跨学科项目成果以及期末反思报告四个部分。其中项目评价不仅关注功能实现,也重视创新性与展示效果,期末反思则要求学生从伦理与未来趋势角度进行思考,体现课程的价值导向。\\\\n\\\\n整体而言,本课程具有六大特色:一是通过学科视角重构技术认知,帮助文科生更好地理解AI本质;二是强调实践导向,每节课都设有可操作的实验环节;三是将伦理思辨贯穿于技术教学之中,培养学生负责任的技术观;四是采用模块化设计,灵活适应不同专业需求;五是紧跟技术前治,关注生成式AI的发展趋势与社会影响;六是鼓励个性化学习与创新,激发学生的主动探索精神。\\\\n\\\\n通过本课程的学习,学生不仅能够系统掌握人工智能的核心知识与技能,更能在真实场景中加以应用,形成可持续发展的数字素养与跨学科创新能力,为今后的学习与职业发展奠定坚实基础。\\\\n \\\\n\\\\n\",\"dataId\":\"file_b7038618d7f1405e9d8d9b79c4a8b460_12039021\",\"dataName\":\"AI课程大纲\",\"display\":true,\"enableSpecifiedModel\":false,\"id\":\"gqhpyjb6l1_file_b7038618d7f1405e9d8d9b79c4a8b460_12039021\",\"rankWeight\":1.0,\"referenceIndex\":2,\"rejectStatus\":false,\"score\":0.99,\"scoreWithWeight\":0.99,\"title\":\"AI课程大纲\",\"webSearch\":false},{\"content\":\"【文档名】:第7周-提示词工程模块堂内练习内容\\\\n【标题】:第7周-提示词工程模块堂内练习内容\\\\npipeline_name:AI基础课知识库\\\\n【正文】:第7周-提示词工程模块堂内练习内容\\\\n\\\\n课堂实时互动练习题:总结与挑战活动\\\\n\\\\n核心目标是帮助学生掌握五种常见的提示技巧,并通过实际动手操作提升其使用生成式AI的能力。为了增强互动性与实操性,课堂上将提供一个类似Playground的网页交互界面(WebUI),供学生实时输入提示词并观察模型输出结果。这种方式可以让学生直观地看到不同提示风格对AI生成内容的影响,从而更好地理解和应用提示工程的基本方法。\\\\n\\\\n练习内容概述\\\\n\\\\n在完成对五种核心提示技巧(结构化提示、少样本学习、思维链提示、ReAct提示和提示迭代)的讲解后,学生将在教师引导下进行一次课堂互动练习。每位学生将被要求:\\\\n\\\\n1.选择一种提示技巧;\\\\n\\\\n2.结合自己的专业背景,尝试撰写一个具体的提示词;\\\\n\\\\n3.在WebUI中输入提示词并查看AI的输出结果;\\\\n\\\\n4.对比预期效果,思考如何优化提示词以获得更理想的回应。\\\\n\\\\n示例引导机制\\\\n\\\\n为了降低初学者的理解巾槛,课堂会展示一个完整的提示词与输出结果的案例,但不会直接告诉学生该提示词的具体写法。学生需要根据提示词的大致描述与最终输出的效果,推测可能使用的提示策略,并尝试复现或改进这一提示词。\\\\n\\\\n这种\\\\\"结果导向\\\\\"的练习方式有助于学生从实际应用出发,理解提示词的设计逻辑,同时也能激发他们结合自身专业背景进行创新尝试的兴趣。\\\\n\\\\n教学支持工具\\\\n\\\\n我们将使用中文无代码平台(如通义千问、文心一言等)作为基础,搭建一个简洁易用的WebUI界面, 模拟Playground的功能。学生无需登录账号即可快速测试提示词,且所有数据均在课堂环境中本地处理,确保教学过程的安全与合规。\\\\n\\\\n核心教学理念\\\\n \\\\n·提示即对话:AI不是黑箱,而是一个可以通过语言引导的智能助手;\\\\n\\\\n·好提示=清晰+有结构+可迭代;\\\\n\\\\n·技术应用离不开专业背景的支持,只有结合学科知识,才能真正发挥AI的潜力;\\\\n\\\\n·无需编程基础,只要会\\\\\"说话\\\\\",就能用好AI。\\\\n \\\\n\\\\n\",\"dataId\":\"file_9c8a13dbb29843fca396a7ef60e4b60f_12039021\",\"dataName\":\"第7周-提示词工程模块堂内练习内容\",\"display\":true,\"enableSpecifiedModel\":false,\"id\":\"gqhpyjb6l1_file_9c8a13dbb29843fca396a7ef60e4b60f_12039021\",\"rankWeight\":1.0,\"referenceIndex\":3,\"rejectStatus\":false,\"score\":0.99,\"scoreWithWeight\":0.99,\"title\":\"第7周-提示词工程模块堂内练习内容\",\"webSearch\":false},{\"content\":\"【文档名】:第7周-提示词工程模块课件内容\\\\n【标题】:第7周-提示词工程模块课件内容\\\\npipeline_name:AI基础课知识库\\\\n【正文】:第7周-提示词工程模块课件内容\\\\n\\\\nTopic 1:什么是提示工程(Prompt Engineering)\\\\n\\\\n第1页:封面页\\\\n\\\\n标题:提示工程(Prompt Engineering)入巾\\\\n\\\\n副标题:与AI高效对话的艺术\\\\n\\\\n脚本:欢迎大家来到第七周的课程的第一小节!今天我们来学习\\\\\"什么是提示工程\\\\\"。通过本节课,你会了解提示工程的基本概念、原理和实际应用。\\\\n\\\\n第2页:提示工程的定义\\\\n\\\\n标题:什么是提示工程?\\\\n\\\\n内容:\\\\n\\\\n·提示工程(Prompt Engineering) =与AI打交道的艺术\\\\n\\\\n·通过精心编写提示词,引导AI产生想要的回答\\\\n\\\\n·类比:阿拉丁神灯——愿望越清楚,结果越满意\\\\n\\\\n图片/风格建议:灯神与许愿的卡通插画\\\\n\\\\n脚本:大家可能会好奇:什么是提示工程?简单来说,提示工程就是与AI打交道的艺术。我们通过精心编写提示词,也就是给AI的指令或问题,来引导大型语言模型产生我们想要的回答。就像拥有一盏阿拉丁神灯,如果你的许愿含糊不清,灯神未必能满足你的期望;但如果描述得清楚具体,得到的结果就更接近心意。提示工程的作用正是在于教会我们如何清楚准确地向AI提问,从而获得高质量答案。\\\\n\\\\n第3页:AI如何\\\\\"理解\\\\\"我们的语言\\\\n\\\\n标题:AI如何\\\\\"理解\\\\\"我们的语言?\\\\n\\\\n内容:\\\\n\\\\n·当前AI(如ChatGPT、 Deepseek) 并不真正\\\\\"理解\\\\\"含义\\\\n \\\\n·AI通过概率预测生成回答\\\\n\\\\n·训练自海量文本,掌握词语和句子的统计模式\\\\n\\\\n·类比:手机输入法的联想功能\\\\n\\\\n图片/风格建议:AI大脑、概率曲线、手机输入法的联想气泡\\\\n\\\\n脚本:那么,AI是如何理解我们的语言的呢?这里需要强调:当前的AI(例如ChatGPT, Deepseek 等大语言模型)并不像人类那样真正\\\\\"理解\\\\\"含义,而更像是在做概率预测。模型阅读了海量文本,通过机器学习掌握了词语和句子的统计模式。当你向它提问时,它会将你的语言转换成内部的数学表示,然后根据训练中学到的模式预测下一步应该输出什么。这有点像我们手机输入法的联想功能——会根据已有的文字猜测你接下来要输入的词,只不过大型语言模型的\\\\\"联想\\\\\"能力强大得多。\\\\n\\\\n第4页:提示质量的重要性\\\\n\\\\n标题:为什么提示质量很重要?\\\\n\\\\n内容:\\\\n\\\\nAI只是\\\\\"猜\\\\\"出一个看起来像答案的回应\\\\n\\\\n·好的提示让模型预测更可靠\\\\n\\\\n·差的提示可能导致偏题或错误回答\\\\n\\\\n·结论:好的回答来自于好的提问\\\\n\\\\n图片/风格建议:对比\\\\\"模糊\\\\\"与\\\\\"清晰\\\\\"指令的图示\\\\n\\\\n脚本:因此,与其说AI理解了你的问题,不如说它猜出了一个看起来像答案的回应。正因为如此,我们输入的提示质量就格外重要:好的提示能让模型的预测更可靠,差的提示可能让模型产生偏题甚至错误的回答。换句话说,好的回答来自于好的提问。\\\\n\\\\n第5页:提示工程的意义\\\\n\\\\n标题:提示工程的意义\\\\n\\\\n主要内容:\\\\n\\\\n优化提问方式,提升AI输出质量\\\\n\\\\n入巾易,精通难\\\\n\\\\n需要技巧,才能让AI输出准确、有用的结果\\\\n \\\\n图片/风格建议:阶梯、目标靶心或\\\\\"入巾\\\\\"到\\\\\"精通\\\\\"的渐变图\\\\n\\\\n脚本:提示工程的意义在于:通过优化提问的方式,我们可以大大提升AI给出满意答案的概率。同学们可能觉得, 跟ChatGPT对话谁不会呀?随便问就行了。但实际上,提示工程是\\\\\"入内易,精通难\\\\\"。简单的提问人人都会,但要让AI输出准确、有用的结果,我们需要一些技巧。\\\\n\\\\n第6页:案例对比   -模糊提示vs.清晰提示\\\\n\\\\n标题:案例对比:模糊提示vs.清晰提示\\\\n\\\\n内容:\\\\n\\\\n| 模糊提示|清晰提示|\\\\n| ---|---|\\\\n|  |\\\\\"请写一篇约300字的短文,主题是人工智能在|\\\\n\\\\n\\\\\"写一篇文章。\\\\\"                        护理行业中的应用,语言生动且易于理解。请\\\\n\\\\n举一个护理工作中使用AI的具体案例。\\\\\"\\\\n\\\\n图片/风格建议:两份文章输出的对比(可用图标或缩略文本表示)\\\\n\\\\n脚本:举个案例对比来体会提示工程的重要性:比如我们想让AI写一篇文章。如果我们只是给出一个非常笼统的指令——\\\\\"写一篇文章。\\\\\"—AI可能无从下手,不知道我们想要什么主题、什么风格、多长的文章,结果往往不尽如人意。但是,如果我们换一种方式,提供一个清晰具体的提示,比如:\\\\\"请写一篇约300字的短文,主题是人工智能在护理行业中的应用,语言生动且易于理解。请举一个护理工作中使用AI的具体案例。\\\\\"这样一来,AI就能按照我们描述的清晰指令去生成内容,写出的文章就更符合我们的期望。这个例子中,我们把一个模糊的请求变得具体明确,AI输出的质量明显提高。这正是提示工程发挥作用的体现。\\\\n\\\\n第7页:总结与启发\\\\n\\\\n标题:总结\\\\n\\\\n主要内容(要点式):\\\\n\\\\n·提示工程=与AI高效沟通的桥梁\\\\n\\\\n·好的提问带来高质量回答\\\\n\\\\n·掌握提示工程,释放AI潜力\\\\n\\\\n图片/风格建议:桥梁、灯泡、AI与人类握手等象征合作的图像\\\\n \\\\n脚本:这个例子中,我们把一个模糊的请求变得具体明确,AI输出的质量明显提高。这正是提示工程发挥作用的体现。希望大家通过这个小节的学习,能够意识到:提示工程是与AI高效沟通的桥梁,好的提问带来高质量的回答。掌握提示工程,能让我们更好地释放AI的潜力。\\\\n\\\\n主题1的选择题\\\\n\\\\n你想让AI写一篇约300字、语言生动易懂、主题为\\\\\"人工智能在护理行业中的应用\\\\\"的短文,并举出一个具体案例。下面哪一个提示 (Prompt) 最符合提示工程的原则,最有可能一次就得到满意的答案?\\\\n\\\\nA.「写一篇文章。」\\\\n\\\\nB.「请写一篇文章,主题是护理。」\\\\n\\\\nC.「你是一名护理信息学专家。请写一篇约300字的短文,说明人工智能在护理行业中的应用,并举一个护理工作中使用AI的具体案例,语言生动、易于理解,分三段呈现。」\\\\n\\\\nD.「写300字,关于护理Al。」\\\\n\\\\n参考答案\\\\n\\\\nC\\\\n\\\\n选项反馈\\\\n\\\\n选项\\\\n\\\\nA\\\\n\\\\n| 反馈说明|\\\\n| ---|\\\\n| 过于笼统:没有任何主题、长度、风格或格式要求,属于\\\\\"含糊提问\\\\\"。模型不知道你想要什么内容或深度,极易跑题或生成与护理无关的文章。|\\\\n\\\\n缺乏关键细节:虽然给出主题\\\\\"护理\\\\\",但仍未\\\\n\\\\n说明篇幅、语言风格、是否需要举例等信息,\\\\n\\\\nB\\\\n\\\\n也未指定角色。结果可能篇幅不符或内容泛泛\\\\n\\\\n而谈。\\\\n\\\\nC                                  最佳提示:①指定角色(护理信息学专家)\\\\n\\\\n保证专业度;(②)日明确字数(约300字)和输\\\\n\\\\n出结构(分三段);③给出主题与案例要求;\\\\n\\\\n④要求语言生动易懂。充分满足\\\\\"清晰具体、\\\\n\\\\n提供上下文、  指定角色、  指明输出格式\\\\\"等提\\\\n \\\\n选项\\\\n\\\\nD\\\\n\\\\n| 反馈说明|\\\\n| ---|\\\\n| 示工程原则,因此最可能一次生成高质量答案。|\\\\n| 信息不完整:只给了字数和主题关键词,没有说明语言风格、是否举例或结构要求,且未说明模型身份。尽管比A/B稍好,但仍缺少足够上下文和格式指令,会导致结果质量不稳定。|\\\\n\\\\n7Topic 2: Prompt提示的结构基础\\\\n\\\\n第1页:封面页\\\\n\\\\n标题:基本提示结构:与AI高效对话的框架\\\\n\\\\n副标题:掌握结构化思维提升AI输出质量\\\\n\\\\n脚本:那么继续开始我们第七周的课程的第二小节!有了上一章节对提示工程的基本认识,我们接下来关注如何构建一个好的提示。\\\\n\\\\n第2页:构建高质量提示的三大支柱\\\\n\\\\n标题:构建高质量提示的三大支柱\\\\n\\\\n内容:\\\\n\\\\n·一个好的Prompt通常包含三个关键要素:\\\\n\\\\n角色(role):这一部分给模型设定身份或上下文\\\\n\\\\no指令(Instruction) :这个部分是核心提问-你具体想让AI做什么。\\\\n\\\\n格式要求(Format) :结构话想要的输出格式\\\\n\\\\n·这三者像\\\\\"三大支柱\\\\\",让提问更有针对性,更高效。\\\\n\\\\n图片/风格建议:三个色块/圆环/支柱形状,分别标注\\\\\"角色\\\\\"\\\\\"指令\\\\\"\\\\\"格式\\\\\",中间用线连接,形成支撑结构的视觉感然后链接在一起。Link the three together to output.\\\\n\\\\n脚本:那么我们如何来构建一个好的提示词呢?总的来说一个精心设计的提示词往往不只是随意的一句话,而是可能包含多个部分,共同为AI指明方向。一般来说,一个完整的Prompt提示可以拆分为几个关键要素,我们这里强调其中最常用的三部分:角色(Role)、指令(Instruction) 和格式要求(Format)。我们可以把这三个要素想象成提示词的\\\\\"三大支柱\\\\\",帮助我们的提问更加有的放矢。\\\\n \\\\n第3页:角色(role))一设定AI的身份\\\\n\\\\n标题:角色(Role) -) 一设定AI的身份\\\\n\\\\n内容:\\\\n\\\\n·1角色是给AI设定身份或语境,让回答更专业、贴合场景。\\\\n\\\\n·例子:\\\\n\\\\n\\\\\"你是一名律师,请解释合同法中的要点\\\\\"\\\\n\\\\n\\\\\"你是一名有经验的护士,请分析以下病例\\\\\"\\\\n\\\\n\\\\\"你现在是我的中文老师,请帮我..\\\\\"\\\\n\\\\n\\\\\"你是一位美食评论家\\\\\"\\\\n\\\\n图片/风格建议:\\\\n\\\\n·人物头像图标+职业服装元素(如法袍、护士帽)感\\\\n\\\\n·对话气泡突出\\\\\"角色\\\\\"设定\\\\n\\\\n脚本:首先是角色(Role) 。这一部分是给模型设定身份或上下文。为什么要这样做呢?因为大型语言模型是通用的,它什么都能聊一点,但如果我们希望得到专业且贴合情境的回答,最好告诉它应以什么身份来回答。举个例子,如果你在法律课上向AI提问,你可以先声明\\\\\"你是一名律师\\\\\"。这样模型在回答时,就会尝试用法律专业人士的口吻和知识去回答问题;又比如在护理场景下,你可以让模型\\\\\"作为一名有经验的护士\\\\\"来解答,它就会更加关注医疗护理方面的细节。设定角色实际上就是提供了回答的语境和视角。它可以是一种职业身份、专家类型,或者特定的语气风格。比如:\\\\\"你现在是我的中文老师,请帮我...\\\\\",模型听到这句,就会以中文老师那样循循善诱的方式回答。再比如:\\\\\"你是一位美食评论家\\\\\",那么回答可能就会多些美食品鉴的语言。通过角色,我们有效地收窄了模型回答的范围,让它更贴合我们需要的领域和风格。\\\\n\\\\n第4页:指令(Instruction)—明确你的需求\\\\n\\\\n标题:指令(Instruction) h)明确你的需求\\\\n\\\\n内容:\\\\n \\\\n·指令是你具体想让AI做什么,必须清晰、具体\\\\n\\\\n·使用清晰的动作动词,例如:解释、总结、列出、比较\\\\n\\\\n·聚焦于具体的概念或任务(与学科相关)\\\\n\\\\n·范围明确,避免模糊的表达\\\\n\\\\n·好指令的要素:\\\\n\\\\n0明确任务类型\\\\n\\\\n指出具体内容\\\\n\\\\n设定范围或限制\\\\n\\\\n·例子:\\\\n\\\\n0例子1:\\\\n\\\\n\\\\\"请总结以下文章的主要观点,并用两到三句话表达。\\\\\"\\\\n\\\\n■\\\\\"总结\\\\\"→明确动作动词(任务类型)\\\\n\\\\n■\\\\\"主要观点\\\\\"→具体内容\\\\n\\\\n■\\\\\"两到三句话\\\\\"→范围/格式要求\\\\n\\\\n0例子2:\\\\n\\\\n\\\\\"请找出病例描述中的关键症状,并解释可能的原因。\\\\\"\\\\n\\\\n■\\\\\"找出\\\\\"→明确动作动词\\\\n\\\\n■\\\\\"病例描述中的关键症状\\\\\"→具体内容\\\\n\\\\n■\\\\\"解释可能的原因\\\\\"→进一步任务/范围\\\\n\\\\n图片/风格建议:\\\\n\\\\n·任务清单图标、放大镜、重点标记符号\\\\n\\\\n例句用不同颜色高亮动词、内容、范围,并用箭头或气泡标出\\\\n\\\\n·右侧留白用于callout说明\\\\n\\\\n脚本:接下来是指令(Instruction),这是提示的核心部分——你具体想让AI做什么。指令一定要清晰、具体,用明确的动作动词,比如\\\\\"总结\\\\\"、\\\\\"解释\\\\\"、\\\\\"列出\\\\\"等。还要聚焦于一个具体的任务或概念,并设定好范围。回想我们之前讲的原则,含糊的请求往往得不到理想结果。所以在编写提示时,指令部分要直截了当。例如,你想让AI帮你总结一段文本,那么指令可以是:\\\\\"请总结以下这段文章的主要观点,并用两到三句话表述。\\\\\"这里\\\\\"总结主要观点\\\\\"就是任务,\\\\\"两到三句话表述\\\\\"则已经带了格式要求。我再举一个例子:假如我们在医疗场景下,有一段病历文本需要分析,指令可以这样写:\\\\\"请找出下面病例描述中的关键症状,并解释这些症状可能指向的潜在问题。\\\\\"这样的指令明确指出任务是提取症状并解释意义。总之,指令部分要让模型一眼就看明白你的具体需求是什么。可以想想,如果把这个任务交给人类同学,对方需要知道哪些信息?我们就尽量在指令里把这些说清楚。\\\\n \\\\n第5页:格式要求((Format)一规定答案的呈现方式\\\\n\\\\n标题:格式要求(Format)-)—规定答案的呈现方式\\\\n\\\\n内容:\\\\n\\\\n·不格式要求让AI输出更符合你的使用场景。\\\\n\\\\n·常见格式要求:\\\\n\\\\n希望答案以段落还是列表形式?((\\\\\"请用项目符号列出...\\\\\")\\\\n\\\\n0希望答案多长、多简洁?(\\\\\"每条不超过20字\\\\\"或\\\\\"回答控制在100字以内\\\\\")\\\\n\\\\no是否需要特定的语气或风格?(\\\\\"用幽默的语调回答\\\\\"或\\\\\"语言专业严谨\\\\\")\\\\n\\\\no是否要遵循某种模板?(\\\\\"按照时间-地点-人物三个方面来描述\\\\\")\\\\n\\\\n或者输出机器可读的格式, 比如JSON、XML表格等 (\\\\\"以JSON格式输出结果\\\\\")\\\\n\\\\n·例子:\\\\n\\\\n \\\\\"请按表格形式列出法律条款的要点,表头包括条例名称和主要内容。\\\\\"\\\\n\\\\n图片/风格建议:\\\\n\\\\n·列表、表格、对话气泡等图标\\\\n\\\\n·色块突出\\\\\"格式\\\\\"关键词\\\\n\\\\n脚本:第三部分是格式要求 (Format)。这一要素经常被忽视,但实际上非常重要。模型给出的答案如果结构混乱、不符合我们需要的格式,即使内容对了,可能还需要我们二次整理。所以在提示中提前说明希望的输出格式,可以省去很多麻烦。格式要求包括很多方面,比如:\\\\n \\\\n·希望答案以段落还是列表形式?(\\\\\"请用项目符号列出...\\\\\")\\\\n\\\\n·希望答案多长、多简洁?(\\\\\"每条不超过20字\\\\\"或\\\\\"回答控制在100字以内\\\\\")\\\\n\\\\n·是否需要特定的语气或风格?(\\\\\"用幽默的语调回答\\\\\"或\\\\\"语言专业严谨\\\\\")\\\\n\\\\n·是否要遵循某种模板?(\\\\\"按照时间-地点-人物三个方面来描述\\\\\")\\\\n\\\\n·或者输出机器可读的格式, 比如JSON、XML表格等(\\\\\"以JSON格式输出结果\\\\\")。\\\\n\\\\n这些格式提示能让AI更好地呈现它的答案,方便我们直接使用。举个例子,如果我们让AI帮忙整理一份法律条文清单,就可以在提示中加上:\\\\\"请按表格形式列出法律条款的要点,表头包括条例名称和主要内容。\\\\\"有了这样的格式指示,AI的回答就很可能已经是排好表格要点的形式,我们拿来就能做PPT或报告了。\\\\n\\\\n第6页:三要素综合示例\\\\n\\\\n标题:三要素综合示例\\\\n\\\\n内容:\\\\n\\\\n·角色:你是一名经验丰富的儿科护士\\\\n\\\\n·指令:请阅儿童病例描述并通俗易懂的语言累出三个护理要点。病例描述:5岁男童,发热39.2℃,咳嗽两天,食欲减退,精神尚可,听诊双肺有轻微罗音。\\\\n\\\\n·格式要求:用项目符号格式展示结果,每个要点不要超过20个字。\\\\n\\\\n·基于三要素的输出示例:\\\\n\\\\n检测体温变化,及时无力降温\\\\n\\\\n0确保患儿充分休息和水分摄入\\\\n\\\\n观察呼吸情况,如有异常及时叫医生\\\\n\\\\n图片/风格建议:\\\\n\\\\n·护士卡通形象,列表图标\\\\n\\\\n·三色分区突出三要素\\\\n\\\\n脚本:现在我们把角色、指令、格式这三要素综合一下,来看一个完整提示词示例,更直观地体会各部分如何配合。假设我们有一个护理专业的应用场景:我们想请AI阅\\\\n \\\\n读一个儿童病例并给出护理要点,而且我们希望回答以要点列表形式呈现。我们可以这样写提示:\\\\n\\\\n\\\\\"你是一名经验丰富的儿科护士,请阅儿童病例描述并通俗易懂的语言累出三个护理要点。病例描述:5岁男童,发热39.2°℃,咳嗽两天,食欲减退,精神尚可,听诊双肺有轻微罗音。请用项目符号格式展示结果,每个要点不超过20个字。\\\\\"\\\\n\\\\n这个提示可以拆解为:\\\\n\\\\n·角角色:\\\\\"你是一名经验丰富的儿科护士\\\\\"——-让模型以儿科护士的专业视角来思考问题;\\\\n\\\\n·指令:\\\\\"阅读病例描述并用通俗易懂的语言列出三个护理要点\\\\\"-明确告诉模型任务是提炼护理要点,语言要求通俗易懂,数量是三个要点;\\\\n\\\\n·格式要求:\\\\\"用项目符号格式展示结果,每个要点不超过20个字\\\\\"一—一规定了回答应该是bullet点形式, 而且对每点的长度做了限制。\\\\n\\\\n可以想见,有了这样的提示,模型会给予一个清晰的回答,:\\\\n\\\\n监测体温变化,及时物理降温\\\\n\\\\n确保患儿充分休息和水分摄入\\\\n\\\\n观察呼吸情况,如有异常及时就医\\\\n\\\\n这样的输出就是我们理想中包含三条护理要点的列表了。这例子里,我们把角色、指令、格式三要素都用上,确保了回答的专业性、准确性和易读性。\\\\n\\\\n小结一下:提示词的结构化能够提高我们提问的有效性。并不是每个场景下都需要把这些要素全部用上,但在设计提示时,心里可以过一遍:\\\\\"我有没有交代背景角色?任务说明清不清楚?需不需要指定格式?\\\\\"这样检查一遍,能让提示更加完善。\\\\n\\\\nTopic 2的选择题\\\\n\\\\n问题:\\\\n\\\\n以下哪一项最能体现\\\\\"格式要求(Format)\\\\\"在结构化提示中的作用?\\\\n\\\\nA.指定AI回答时要用律师的身份\\\\n\\\\nB.让AI用项目符号列出要点,每条不超过20字\\\\n\\\\nC.要求AI解释某个法律概念\\\\n\\\\nD.让AI用幽默的语气回答\\\\n\\\\n参考答案:\\\\n \\\\nB.让AI用项目符号列出要点,每条不超过20字\\\\n\\\\n选项反馈\\\\n\\\\n| 选项反馈说明这个选项属于\\\\\"角色(Role)\\\\\"的设定,即让AI以特定身份或视角来回答问题。角色设定可以A让回答更贴合专业领域,但它并没有规定答案的呈现形式,所以不属于\\\\\"格式要求\\\\\"正确!这就是\\\\\"格式要求(Format)\\\\\"的典型例子。你明确告诉AI答案要用项目符号(bullet points)来列出,而且每条要点的字数有具体B限制。这种要求可以帮助你直接获得结构清晰、方便使用的输出,减少后期整理的工作量。这个选项是\\\\\"指令(Instruction)\\\\\",即你在告诉AI需要完成什么具体任务,比如\\\\\"解释\\\\\"、\\\\\"总C结\\\\\"或\\\\\"分析\\\\\"。虽然指令很重要,但它没有涉及答案的具体呈现方式,所以不属于\\\\\"格式要求\\\\\"。这个选项涉及的是\\\\\"表达风格\\\\\"或\\\\\"语气\\\\\",有时可以作为格式要求的补充,但它本质上是对回D答语气的规定,而不是对答案结构或输出形式的要求。格式要求通常更关注答案是以列表、表格、段落等形式输出。|\\\\n| ---|\\\\n\\\\nTopic 3: Few-shot Learningg少样本提()第1页:封面页\\\\n\\\\n标题:少样本学习\\\\n\\\\n副标题:用实例让AI\\\\\"看懂\\\\\"你的需求\\\\n\\\\n脚本:那么继续开始我们第七周的课程的第三小节!上一章我们重点学习了一下提示工程的基础结构,那么这个小节我们延展的学一下提示工程的另一个技巧 一少样本提示(Few-shot learning) 用实例让AI\\\\\"看懂你的需求。\\\\n \\\\n第2页:什么是少样本学习\\\\n\\\\n标题:什么是少样本学习\\\\n\\\\n内容:\\\\n\\\\n·定义:少样本学习((Few-shot learning)是一种通过给人工智能提供少量你想要的示例来训练它的方法。\\\\n\\\\n·类比:像给新同学做示范,他就能模仿你的做法\\\\n\\\\n·1作用:让AI更准确地模仿你的思路和表达方式\\\\n\\\\n图片建议:\\\\n\\\\n·左侧为老师示范,右侧为学生模仿(卡通风格)\\\\n\\\\n·下箭头连接\\\\\"示例\\\\\"与\\\\\"AI输出\\\\\"\\\\n\\\\n脚本:少样本提示技巧。这个名字听起来有点学术,其实概念很直观:当我们想让AI按照某种特定的模式或风格回答时,可以在正式提问之前,先给它提供几个示例(样本)。模型通过这些示例就能\\\\\"明白\\\\\"我们想要的回答格式或风格,然后再根据我们给的新问题,沿着示例的路子生成答案。先说定义:Few-shot提示指的是, 在你的prompt中不仅包含最后的问题,还包括一系列范例问答或范例任务的输入输出。简单来说,就是先教后问:先举例子给AI看,然后让它仿照例子的方式回答你最后的问题。举个通俗的比喻:这有点像我们做功课时先看了两道例题的解答,再去解第三道类似的问题。有了前面的参考,第三道题往往更好上手。AI模型在提示中看到前面的示例后,也会在潜意识里学到:\\\\\"哦,原来遇到这种提问,该按照这种风格来回答。\\\\\"\\\\n\\\\n第3页:什么时候使用少样本学习?\\\\n\\\\n标题:什么时候使用少样本学习?\\\\n\\\\n内容:\\\\n\\\\n单靠文字提示效果不理想\\\\n\\\\n·需要特定格式或风格(如写诗,专业用语)\\\\n\\\\n·涉及复杂或专业判断的情况\\\\n\\\\n·希望AI能处理高级概念、做出细致区分,或遵循复杂的逻辑结构。\\\\n\\\\n图片建议:\\\\n\\\\n·对比图:zero-shot和few-shot输出的差异\\\\n \\\\n·格式、风格、专业、批量等关键词图标\\\\n\\\\n脚本:那么,什么时候我们需要使用少样本学习提示呢?一个典型场景是:当简单文字提示效果不理想时。简单文字提示就是不提供任何示例,直接发问。很多情况下零样本已经能得到不错的答案,但有时模型的回答风格、精准度不符合要求。这时少样本学习就能派上用场了。比如:\\\\n\\\\n·需要特定格式或风格:假设我们希望AI的回答遵循严格的格式,或者模仿某种语气。如果直接要求,模型可能拿捏不准。但如果给它一两个范例,它就会模仿范例格式输出。例如你要它写诗,用几首小诗做示例,再让它写新的,它更能对仗出类似风格。\\\\n\\\\n·1任务较复杂或专业:当问题涉及一些专业领域知识或特定解题过程时,提供示例可以让模型参考解题思路。尤其对于推理题,少样本学习示例可以包含解决问题的过程,这样模型在新问题上也会尝试类似的推理路径。\\\\n\\\\n·车输出需要一致性:比如你要让AI批量处理多条相似的任务(翻译句子、分类短语等),给一个例子翻译或分类,模型对后续类似输入就能保持一致的标准。\\\\n\\\\n第4页:少样本提示的结构\\\\n\\\\n标题:少样本提示的结构\\\\n\\\\n内容:\\\\n\\\\n·结构:\\\\n\\\\no一个明确的任务说明\\\\n\\\\n02-3组\\\\\"输入-输出\\\\\"示例\\\\n\\\\no你的新问题/输入\\\\n\\\\n·关键要素:\\\\n\\\\n使用2-3个示例(太多会干扰AI)\\\\n\\\\n输入/输出格式保持一致\\\\n\\\\n示例应准确展示你想要的模式\\\\n\\\\n0示例要具体、清晰\\\\n\\\\np最后给出明确的新任务指令\\\\n\\\\n图片建议:\\\\n \\\\n·三步流程图:任务→示例→新输入\\\\n\\\\n·箭头串联,突出\\\\\"先例后问\\\\\"\\\\n\\\\n脚本:少样本提示的结构通常是这样的:在最终要问的问题之前,列出若干示例,每个示例包含一个输入和对应的输出。然后再提出我们真正的问题/输入。模型会把前面的示例当作对话或任务的一部分,从而推断出回答的模式。\\\\n\\\\n第5页:简单领域案例\\\\n\\\\n标题:法律领域少样本提示例子演示\\\\n\\\\n内容:\\\\n\\\\n·任务:用正式,简明风格解释法律概念\\\\n\\\\n·例子1:\\\\n\\\\no问:简要解释什么事过失责任?\\\\n\\\\n0答案:过失责任是指因行为人疏忽大意或未尽合理注意义务而导致他人受到损害需承担的法律责任。例如司机未注意路况撞伤行人,就属于过失导致的侵权,需要承担相应的赔偿责任。\\\\n\\\\n·例子2:\\\\n\\\\no问:简要解释什么是合同违约?\\\\n\\\\n答案:合同违约是指一方当事人未按照合同约定履行义务所产生的法律后果。例如卖方未按时交货构成违约,需根据合同约定承担赔偿等违约责任。\\\\n\\\\n·你的问题(新问题):\\\\n\\\\no问:简要解释什么是知识产权侵权。\\\\n\\\\n答案(让AI模仿上面风格作答的结果):知识产权侵权是指未经权利人许可而使用其知识产权并造成损害的行为,需要承担相应的法律责任。例如未经作者同意擅自转载其作品并营利,就属于侵犯著作权的行为。\\\\n\\\\n·注意:few-shot 示例不宜过多\\\\n\\\\n图片建议:\\\\n\\\\n法律天平、问答框\\\\n\\\\n·颜色分区突出\\\\\"问-答\\\\\"结构\\\\n \\\\n脚本:我们来看一个具体案例,用few-shot提示展示其效果。假设我们有一个法律问答的任务,希望AI用比较正式、简明的风格来回答法律概念。零样本情况下,直接问法律问题,AI可能回答风格不统一或不够严谨。而通过提供示例,我们可以引导它。你们可以用30秒,看一下页面的这个例子。\\\\n\\\\n(等待30秒)\\\\n\\\\n好的,我们一起看一下这个例子。在这个提示中,我们提供了两个示例问答:\\\\n\\\\n·元示例1问\\\\\"过失责任\\\\\"是什么,答案里给出了定义并举了例子,语言比较正式且简洁;\\\\n\\\\n·示例2问\\\\\"合同违约\\\\\",答案同样给出定义再举例,格式和语气与示例1一致。\\\\n\\\\n接着我们提出真正想问的问题:\\\\\"知识产权侵权是什么?\\\\\"并让模型作答。由于有前面两个示例的指导,模型很可能按照类似的风格来回答。例如,模型可能生成:\\\\n\\\\n\\\\\"答:知识产权侵权是指未经权利人许可而使用其知识产权并造成损害的行为,需要承担相应的法律责任。例如未经作者同意擅自转载其作品并营利,就属于侵犯著作权的行为。\\\\\"\\\\n\\\\n可以看到,模型的回答风格和结构模仿了示例:先定义概念,再举例说明,语气正式且内容准确。通过few-shot,我们成功地让AI对齐到了我们想要的回答模式。如果没有这些示例,模型也许仍能答对概念,但可能不会这么有条理地给例子,或者用词上不够正式。\\\\n\\\\n需要注意的是,few-shot示例不宜过多,一般1到5个示例已经能明显影响输出,但如果给太多示例,提示会变长,占用模型的输入空间,而且可能让模型在细节上过度拟合示例。我们要挑代表性强的例子给模型看。\\\\n\\\\n主题3的选择题:\\\\n\\\\n问题:在以下哪种情况下,使用\\\\\"少样本提示示 (Few-shot Prompting) \\\\\"最能显著提升AI的输出效果?\\\\n\\\\nA.你需要AI快速回答一个事实性问题,如:\\\\\"中国的首都是哪里?\\\\\"\\\\n\\\\nB.你想让AI用特定格式写一份会议纪要,例如包括时间、地点、参与人和总结要点\\\\n\\\\nC.你希望AI生成一段随机的小说情节,没有具体风格或结构要求\\\\n\\\\nD.你要求AI翻译一段标准英文新闻句子成中文\\\\n \\\\n参考答案:\\\\n\\\\nB.你想让AI用特定格式写一份会议纪要,例如包括时间、地点、参与人和总结要点选项反馈:\\\\n\\\\n| 选项|反馈说明|\\\\n| ---|---|\\\\n|  |这个任务非常简单且标准化,通常使用零样本|\\\\n|  |提示(zero-shot prompting) 就能得到准确答案。不需要提供示例来引导模型输出格式或|\\\\n|  |风格。|\\\\n\\\\nA\\\\n\\\\n正确!这是一个非常适合使用少样本提示的场\\\\n\\\\n景。通过提供1-3个格式规范的会议纪要示\\\\n\\\\nB\\\\n\\\\n例,可以让AI明确了解你期望的输出结构和内\\\\n\\\\n容要素,从而生成更符合预期的回答。\\\\n\\\\n如果对输出没有具体格式或风格要求,那么提\\\\n\\\\n供示例可能反而会限制AI的创造力,或者导致\\\\n\\\\nC\\\\n\\\\n其偏离自由发挥的方向。这种情况下,零样本\\\\n\\\\n提示通常更适合。\\\\n\\\\n| 翻译属于高度结构化任务,尤其对于常见语言对(如英译中),AI已经训练得非常成熟。在|\\\\n| ---|\\\\n\\\\nD\\\\n\\\\n这种情况下,  即使不提供示例,也能获得高质\\\\n\\\\n量结果,因此few-shot提示并非必要。\\\\n\\\\nTopic 4: Chain-of-Thought提示示思维7提示)\\\\n\\\\n第1页:封面页\\\\n\\\\n标题:Chain-of-Thought提示(思维链提示)\\\\n\\\\n副标题:让AI像人一样\\\\\"链式思考\\\\\",逐步推理,提升复杂问题解答的可靠性\\\\n\\\\n脚本:本章节,我们来学习另一个提示工程的重要技术 ! Chain-of-Thought 提示,中文可以叫**\\\\\"思维链提示\\\\\"。这是提示工程中非常强大的一种技巧,顾名思义,它让模型像人一样链式地思考**。\\\\n\\\\n第2页:什么是思维链提示法?\\\\n \\\\n标题:什么是思维链提示法?\\\\n\\\\n内容:\\\\n\\\\n·定义:要求AI在给出最终答案之前,逐步展示其推理过程。\\\\n\\\\n·类比:人做复杂题会先列公式、再算步骤、最后得答案\\\\n\\\\n图片/风格建议:\\\\n\\\\n·\\\\\"问题→步骤1→步骤2→结论\\\\\"流程图\\\\n\\\\n·人和AI思考泡泡对比\\\\n\\\\n脚本:那么什么是链式思维呢?简单来说,就是把一个复杂问题拆解成一连串较小的推理步骤,一步一步得出结论。通常,人类在解决复杂问题时会在脑海中逐步推演,比如做数学题会先列公式,再算步骤,再得答案。Chain-of-Thought提示就是鼓励Al也显式地走这样的过程,而不是直接蹦出答案。\\\\n\\\\n第3页:思维链提示是怎么工作的?\\\\n\\\\n标题:思维链提示是怎么工作的?\\\\n\\\\n内容:\\\\n\\\\n·要求AI\\\\\"逐步思考\\\\\"问题\\\\n\\\\nAI将复杂任务拆解为逻辑步骤\\\\n\\\\n在每一步中展示其推理过程\\\\n\\\\n·十形成一条\\\\\"思维链\\\\\",最后一环才是结果\\\\n\\\\n图片/风格建议:\\\\n\\\\n·链条/阶梯式流程图,每环代表一个推理步骤\\\\n\\\\n·\\\\\"分步\\\\\"关键词高亮\\\\n\\\\n脚本:我们在这里定义一下:在提示中使用Chain-of-Thought,就是让模型逐步推理再回答。用最简单的例子来说,我们可以通过在提示里加入诸如\\\\\"请分步骤思考\\\\\"或者\\\\\"让我们一步一步推理这个问题\\\\\"的指示,来触发模型输出中间推理步骤。这些中间步骤就像是一条\\\\\"思维链\\\\\",最后一环才是结果。另一种方法可以使用我们上一个小节学到的关于少样本提示的技巧,我们可以在少样本提示示例里直接展示带推理过程的解答,让模型学会模仿。在这些示例中,每个问题的答案不是直接给结果,而是先写出推理过程,再给出结论。模型看到这样的范例,自然在新问题上也会按步骤列出思路。\\\\n \\\\n第4页:思维链的优势\\\\n\\\\n标题:思维链的优势\\\\n\\\\n内容:\\\\n\\\\n·复杂推理中的错误\\\\n\\\\n·让AI的逻辑清晰可见、便于验证\\\\n\\\\n·每一步都简单明确,结果更准确\\\\n\\\\n·帮助你理解答案背后的\\\\\"原因\\\\\"\\\\n\\\\n·提高AI的可解释性和可靠性\\\\n\\\\n·特别适用于需要批判性思维的专业领域\\\\n\\\\n图片/风格建议:\\\\n\\\\n·放大镜+链条,突出\\\\\"可检查、可解释\\\\\"\\\\n\\\\n·\\\\\"错误\\\\\"与\\\\\"正确\\\\\"对比图\\\\n\\\\n脚本:为什么CoT有用呢?因为让模型把思考过程显式写出来,可以减少它犯逻辑错误的概率。当问题复杂时,如果不鼓励逐步推理,模型有时会图省事儿直接给一个可能的答案,但那答案可能错或者缺乏依据。而如果我们要求它一步步推导,每一步都比较简单明确,最后得到的结果往往更准确。而且,我们作为人类读者也能看到它的推理过程,便于理解回答从何而来。特别是在需要批判思维专业领域。\\\\n\\\\n第5页:案例对比\\\\n\\\\n标题:案例对比\\\\n\\\\n内容:\\\\n\\\\n·普通提问(无思维链提示)\\\\n\\\\no问题:\\\\\"患者发烧、咳嗽,呼吸急促,请问可能的诊断是什么?\\\\\"\\\\n\\\\n回答:\\\\\"可能是肺炎\\\\\"\\\\n \\\\n·思维链提示:\\\\n\\\\n·问题:\\\\\"患者发烧、咳嗽,呼吸急促,请一步一步分析患者症状并给出可能的诊断?\\\\\"\\\\n\\\\n·回答:\\\\\"第一,患者发烧且咳嗽,说明存在感染的迹象,多见于呼吸道感染。第二,出现呼吸急促,提示下呼吸道可能受累,比如肺部感染。结合以上症状,最可能的诊断是肺炎。此外,也需考虑支气管炎,但高烧更倾向于肺炎。综上所述,最可能的是肺炎。\\\\\"\\\\n\\\\n图片/风格建议:\\\\n\\\\n·左右分栏:左为\\\\\"无CoT\\\\\",右为\\\\\"有CoT\\\\\"\\\\n\\\\n·医学图标+推理链图\\\\n\\\\n脚本:让我们通过案例对比来感受一下\\\\\"思维链提示\\\\\"的效果。考虑一个稍微复杂的问题场景,比如一个医学小诊断:问题:\\\\\"患者发烧、咳嗽,呼吸急促,请问可能的诊断是什么?\\\\\"没有使用思维链提示时,模型也许会直接给出一个简短回答,比如:\\\\\"可能是肺炎。\\\\\"这个回答听上去有道理,但我们不知道它如何得出这个结论,也不确定它是否考虑了所有症状。万一有其他可能,比如支气管炎、哮喘等,没有推理过程我们无法判断模型是不是凭直觉\\\\\"猜\\\\\"的。\\\\n\\\\n现在我们应用思维链提示来提问,同样的问题但加上指引:\\\\\"请一步一步分析患者症状并给出可能的诊断。\\\\\"这相当于明确要求模型列出推理过程。模型这次的回答可能会像这样展开:\\\\\"第一,患者发烧且咳嗽,说明存在感染的迹象,多见于呼吸道感染。第二,出现呼吸急促,提示下呼吸道可能受累,比如肺部感染。结合以上症状,最可能的诊断是肺炎。此外,也需考虑支气管炎,但高烧更倾向于肺炎。综上所述,最可能的是肺炎。\\\\\"\\\\n\\\\n对比两种回答,可以明显看出:使用了思维链提示后,模型给出了逐步推理的过程。它先考虑每个症状分别意味着什么,然后综合推理,最后才得出\\\\\"肺炎\\\\\"这个结论。这样的回答不仅更准确可信(因为我们看到了推理链条),也更有教学意义(让提问者明白了为什么会是这个诊断)。而直接回答\\\\\"可能是肺炎\\\\\"的版本虽然简洁,但缺乏依据支撑。如果当时正确答案不是肺炎,模型可能就误导了我们;而有了推理步骤,我们至少知道模型考虑过什么,可以发现如果它中间哪个推理不对。这个案例说明,在复杂问题上,思维链提示往往能提升AI解题的可靠性。\\\\n\\\\n第6页:思维链适用场景\\\\n\\\\n标题:思维链适用场景\\\\n \\\\n内容:\\\\n\\\\n·多步骤推理任务:\\\\n\\\\n0数学题(分布计算)\\\\n\\\\n逻辑推理,谜题\\\\n\\\\n医学诊断,法律分析\\\\n\\\\n·只要设计复杂思考,思维链都值得一试\\\\n\\\\n图片/风格建议:\\\\n\\\\n·不同行业图标:数学、法律、医学等\\\\n\\\\n阶梯式流程或环形流程图\\\\n\\\\n脚本:思维链技巧特别适用于多步骤推理场景。数学问题是经典例子:比如一道数学应用题,有多步计算,如果直接让模型回答,它可能一下子给错答案;但如果让它先列出计算过程,就像我们手算分步写草稿纸那样,最后答案往往正确率更高。再如逻辑推理题、谜语等等,需要考虑多个条件约束的题目,思维链也能帮助模型逐条理清思路。此外,在医学诊断、法律分析等需要综合分析的领域,这种逐步推理的方式也十分有用——就像刚才医疗案例中那样,或者在法律分析中逐条检查法条和事实再下结论。可以说,凡是涉及复杂思考的问题,思维链提示都是值得一试的方法。\\\\n\\\\ntopic 4的选择题:\\\\n\\\\n问题:以下哪种场景最适合使用Chain-of-Thought(思维链)提示?\\\\n\\\\nA.让AI直接回答\\\\\"中国的首都是哪个城市?\\\\\"\\\\n\\\\nB.让AI写一首关于春天的诗\\\\n\\\\nC.让AI分析患者发烧、咳嗽、呼吸急促的可能病因,并给出诊断依据\\\\n\\\\nD.让AI将100条用户评论分类为\\\\\"好评\\\\\"或\\\\\"差评\\\\\"\\\\n\\\\n参考答案:\\\\n\\\\nC.让AI分析患者发烧、咳嗽、呼吸急促的可能病因,并给出诊断依据\\\\n \\\\n选项反馈:\\\\n\\\\n选项\\\\n\\\\nA\\\\n\\\\nB\\\\n\\\\n| 反馈说明|\\\\n| ---|\\\\n| 这是一个简单的事实性问题,不需要多步推理。AI可以直接给出答案(北京),使用思维链提示反而冗余。|\\\\n| 诗歌创作属于创意性任务,需要自由发挥而非逻辑推理。思维链提示更适合需要结构化分析|\\\\n\\\\n的场景。\\\\n\\\\n正确!医学诊断需要综合症状、排除可能性并\\\\n\\\\n逐步推理,这正是思维链提示的典型应用场\\\\n\\\\nC                                   景。通过分步骤分析症状(如发热→感染可\\\\n\\\\n能,咳嗽→呼吸道问题,呼吸急促→肺部受\\\\n\\\\n累),AI的结论会更可靠且可验证。\\\\n\\\\nD\\\\n\\\\n| 分类任务通常不需要复杂推理,直接使用指令(如\\\\\"请分类以下评论\\\\\")或简单示例即可。思维链提示在此场景中价值有限。|\\\\n| ---|\\\\n\\\\nTopic 5:提示迭代(Iterative Prompting)\\\\n\\\\n第1页:封面页\\\\n\\\\n标题:提示迭代(Iterative Prompting)\\\\n\\\\n副标题:用\\\\\"试错-优化-再试\\\\\"的循环,打磨出满意的AI回答\\\\n\\\\n脚本:通过前几个章节的学习,现在你已经掌握了,提示词工程的基础和几个重要的技巧,接下来,本章节我们来讲一个在提示工程中非常实用且务必掌握的技巧的一个方法,提示迭代。\\\\n\\\\n第2页:什么是提示迭代?\\\\n\\\\n标题:什么是提示迭代?\\\\n\\\\n内容:\\\\n\\\\n·很少有人能第一次就写出完美提示\\\\n \\\\n·提示迭代=把和AI的交互看作循环:每次给出提示→AI回答→你评估→有针对性地修改提示→再问\\\\n\\\\n·这个过程像写文章反复润色,提示词也可以灵活调整\\\\n\\\\n·为什么迭代很重要:\\\\n\\\\no把\\\\\"好的提示\\\\\"变成\\\\\"优秀的提示\\\\\"\\\\n\\\\n0长期来看,通过更优结果节省时间\\\\n\\\\n0教你理解AI是如何解读语言的\\\\n\\\\n0是专业使用AI的必备技能\\\\n\\\\n帮助你建立与AI沟通的专业能力\\\\n\\\\n图片/风格建议:\\\\n\\\\n·\\\\\"编辑-反馈-再编辑\\\\\"循环流程图\\\\n\\\\n·书稿-红笔修改-定稿的视觉元素\\\\n\\\\n脚本:其实在前面的内容中,我们已经多次暗示过这一点:很少有谁能第一次就写出完美的提示,无论是专家还是新手,都需要一个不断试验-改进的过程。所以提示迭代讲的就是如何逐步打磨你的提示,直到AI给出让你满意的答案。提示迭代就是指你不要指望一杆进洞,而是把和AI的交互看作一个循环过程。每一轮你给出提示,模型给你一个回答,你评估一下这个回答哪儿好哪儿不好,然后有针对性地修改提示再问一遍。经过几轮下来,AI的回答通常会有明显改进,更接近你想要的。这种逐步优化提示的过程,就是提示迭代。它强调一个理念:Prompt不是写下就定死的,可以灵活调整。就像写文章会多次修改润色一样,写提示词也应该动态优化。\\\\n\\\\n第3页:提示迭代的流程\\\\n\\\\n标题:提示迭代的流程\\\\n\\\\n内容:\\\\n\\\\n·初始提示:草拟第一版,提交模型\\\\n\\\\n·不模型响应:AI给出答案\\\\n\\\\n·用户评估:对比预期,找出不满意的地方\\\\n\\\\n·修改提示:有针对性地补充、澄清、优化\\\\n \\\\n·再次询问:提交新提示,看效果\\\\n\\\\n·重复评估-修改-再询问,直到满意为止\\\\n\\\\n图片/风格建议:\\\\n\\\\n·用流程图或螺旋图可视化\\\\n\\\\n·每个步骤用不同颜色区分,箭头连接\\\\n\\\\n脚本:我们快速的看一下提示迭代的基础流程。这个流程看似平淡无奇,其实几乎每个用好AI的人都会在背后做这样的循环。首轮提示就好比你和AI交个底,如果它答偏了,你就再拉回来。通过迭代,我们可以逐渐逼近理想答案,而不是一下子全指望首次就完美。模型有时就像个按你要求作画的画家,你不断告诉他\\\\\"这里颜色深一点,那边线条细一点\\\\\",几次来回画作就精致了。\\\\n\\\\n第4页:为什么提示迭代很重要?\\\\n\\\\n标题:为什么提示迭代很重要?\\\\n\\\\n内容:\\\\n\\\\n·语言模型无法读心,第一次很难覆盖所有需求\\\\n\\\\n·通过迭代可以不断补充遗漏、纠正误解、优化表达\\\\n\\\\n·每次反馈都是\\\\\"调教\\\\\"AI,最终答案质量远高于初版\\\\n\\\\n就像指导画家:不断微调,作品越来越接近理想\\\\n\\\\n图片/风格建议:\\\\n\\\\n·\\\\\"画家-多次修改-成品画\\\\\"对比\\\\n\\\\n·\\\\\"对话气泡-反馈-再对话\\\\\"流程\\\\n\\\\n脚本:为什么提示迭代很重要?因为语言模型再强大,也无法读心。第一次你可能没想到要说明某个要求,而AI不知道却不给,你一看\\\\\"哦我漏说了这点\\\\\",下次补上,结果就更好了。或者模型第一次理解错了你的意思,给了偏差的答复,那么你下次可以直接在提示里纠正:\\\\\"上次你提到X,其实我需要的是Y,请重新..\\\\\"。另外,有时候模型回答暴露出它的信息盲区,比如提到了某错误细节—那下一轮我们就可以在提示中加入正确信息,或者干脆提示它避免某方面输出。总之,通过迭代,我们把模型朝着正确方向一步步引导,就像调教学生一样,不断纠错、补充,最终答案质量会远远好于一开始的水平。\\\\n \\\\n第5页:实际案例\\\\n\\\\n标题:实际案例-法律概念解释\\\\n\\\\n内容:\\\\n\\\\n·初始提示:\\\\\"解释一下法律中的过失和故意的区别。\\\\\"\\\\n\\\\nAI回答:过失是指行为人应当预见但因疏忽大意没有预见以致发生有害结果的心理态度,故意是行为人明知自己的行为会发生危害结果并且希望或放任这种结果发生的心理态度。两者区别在于主观心理状态不同。\\\\n\\\\n·第一次迭代:\\\\\"请用简单易懂的语言解释,并分别举一个日常例子。\\\\\"\\\\n\\\\nAI回答:在法律上,过失指的是一个人本来应该预见到自己的行为可能会造成不好的后果,但因为没注意或大意,没有预见,结果把坏事干了。简单说就是\\'不是故意但因为疏忽犯了错。比如:小张开车时在玩手机,没有注意红灯撞到了人。这就是过失造成的事故,因为他本来应该小心驾驶却疏忽了。而故意指的是一个人明明知道自己的行为会产生不好的后果,而且就是想要这么做或放任它发生。也就是说他是有意识地去做坏事。比如:小李对邻居不满,故意把垃圾倒在邻居家巾口,想让邻居难堪。这种就是故意的行为。两者区别在于:过失是\\'不小心\\'导致的,而故意是\\'有意\\'为之。\\\\n\\\\n·第二次迭代:\\\\\"最后请用一两句话总结两者区别要点。\\\\\"\\\\n\\\\nAI回答:总之,过失是不小心犯错,故意是有意犯错,这就是两者的根本区别。\\\\n\\\\n图片/风格建议:\\\\n\\\\n·三步对比卡片:初稿-改进-最终版\\\\n\\\\n·法律天平/对话气泡\\\\n\\\\n脚本:我们来看一个实际案例,感受提示迭代带来的变化。想象一个场景:一位法律专业的同学在自学,需要AI解释一个法律概念,比如\\\\\"过失\\\\\"和\\\\\"故意\\\\\"的区别,并举例说明。但这位同学没有AI提示经验,初始提示可能就写了:\\\\\"解释一下法律中的过失和故意的区别。\\\\\"这样的提示不算差,但是比较笼统。模型第一次的回答也许是这样的:\\\\\"过失是指行为人应当预见但因疏忽大意没有预见以致发生有害结果的心理态度;故意是行为人明知自己的行为会发生危害结果并且希望或放任这种结果发生的心理态度。两者区别在于主观心理状态不同。\\\\\"\\\\n \\\\n模型给的是法律教科书式定义,问题在于:语言生涩,普通人可能难以马上理解,而且它没有举例子。提问的同学一看,觉得太学术化了,不够通俗。那么他开始评估:需要回答更通俗易懂、加上例子。于是他修改提示,第二版提示也许这样:\\\\n\\\\n\\\\\"请用简单易懂的语言解释法律中的过失和故意的区别,并分别举一个日常生活中的例子来说明。\\\\\"\\\\n\\\\n模型收到这新的明确要求,第二次回答可能就好了很多:\\\\n\\\\n\\\\\"在法律上,过失指的是一个人本来应该预见到自己的行为可能会造成不好的后果,但因为没注意或大意,没有预见,结果把坏事干了。简单说就是\\'不是故意但因为疏忽犯了错\\'。比如:小张开车时在玩手机,没有注意红灯撞到了人。这就是过失造成的事故,因为他本来应该小心驾驶却疏忽了。\\\\n\\\\n而\\\\n\\\\n故意指的是一个人明明知道自己的行为会产生不好的后果,而且就是想要这么做或放任它发生。也就是说他是有意识地去做坏事。比如:小李对邻居不满,故意把垃圾倒在邻居家巾口,想让邻居难堪。这种就是故意的行为。两者区别在于:过失是\\'不小心\\'导致的,而故意是\\'有意\\'为之。\\\\\"\\\\n\\\\n看看这次的回答,是不是清楚多了?定义用大白话说出来,还有生活例子帮助理解。同学觉得基本满意。不过也许还有一点可以更好:答案有点长,他想要一个要点总结。那么他可以再迭代一次,第三版提示加上:\\\\\"最后请用一两句话总结两者的区别要点。\\\\\"这样模型会在上述回答末尾再补一句总结:\\\\\"总之,过失是不小心犯错,故意是有意犯错,这就是两者的根本区别。\\\\\"\\\\n\\\\n经过这一连串迭代,这位同学最终拿到了一个通俗易懂、信息完整的答案,远胜于初版的生涩定义。这就是提示迭代带来的收益。从初始到最终,提示变了三次,模型的答案品质一步步提升。\\\\n\\\\n通过这个案例可以体会:迭代的每一步都有明确目标(第1次让语言通俗+加例子,第2次再加总结要点),我们针对性调整提示,就像调参一样在优化输出。这要求我们在评估模型回答时,要学会发现问题所在,然后想:\\\\\"我能在提示里加入什么来解决这个问题?\\\\\"这实际上是一种与AI协作的思维:模型给你草稿,你指导模型修改,反复交互,直到得到满意作品。\\\\n\\\\n总而言之:别怕多问几次!把和AI交流当成一个渐进过程,善用每次反馈去完善下一次提问。真正熟练的提问者,绝不是第一次就问得十全十美,而是懂得不断逼近完美答案的人。\\\\n\\\\ntopic 5的选择题:\\\\n \\\\n问题:在使用AI写作或问答时,为什么\\\\\"提示迭代(Iterative Prompting)\\\\\"是一种非常重要的技巧?\\\\n\\\\nA.因为AI每次的回答都是完全随机的,必须多试几次才有可能碰到好答案\\\\n\\\\nB.因为通过多轮修改和反馈,可以逐步优化提示,让AI输出更接近你的真实需求\\\\n\\\\nC.因为AI只能理解非常简单的指令,复杂任务无法完成\\\\n\\\\nD.因为每次修改提示都会让AI忘记之前的内容\\\\n\\\\n参考答案:\\\\n\\\\nB.因为通过多轮修改和反馈,可以逐步优化提示,让AI输出更接近你的真实需求\\\\n\\\\nB\\\\n\\\\n| 选项|反馈说明|\\\\n| ---|---|\\\\n| A|AI的回答并不是完全随机的,而是根据你的提示和上下文生成的。多次尝试的意义在于优化提示,而不是\\\\\"碰运气\\\\\"|\\\\n|  |正确!提示迭代的核心就是通过反复调整和反馈,让AI的回答越来越符合你的要求。这是高效使用AI的关键方法。|\\\\n|  |AI可以完成复杂任务,只要你的提示足够清晰具体。迭代的作用是让复杂任务的提示越来越完善.|\\\\n|  |实际上,每次你修改提示,AI会根据新提示重新生成答案。迭代的价值在于你能不断补充和调整需求,而不是让AI\\\\\"遗忘\\\\\"|\\\\n\\\\nC\\\\n\\\\nD\\\\n \\\\n\\\\n\",\"dataId\":\"file_b732ae99b8874f6a893e5211bdd38b19_12039021\",\"dataName\":\"第7周-提示词工程模块课件内容\",\"display\":true,\"enableSpecifiedModel\":false,\"id\":\"gqhpyjb6l1_file_b732ae99b8874f6a893e5211bdd38b19_12039021\",\"rankWeight\":1.0,\"referenceIndex\":4,\"rejectStatus\":false,\"score\":0.99,\"scoreWithWeight\":0.99,\"title\":\"第7周-提示词工程模块课件内容\",\"webSearch\":false}]'), ApplicationThought(thought=None, action_type='api', response=None, action_name='长期记忆检索', action='memory', action_input_stream='{\"memory_id\":\"748182d5281c4032a10e70085ce6aea0\",\"query\":\"这节课有什么内容\"}', action_input=None, observation='[\"用户的学习方式（用户偏好的学习方式，比如案例分析、图解、分步讲解）：案例分析, 分步讲解\",\"用户的知识水平（用户对课程内容的整体掌握程度，比如初级 / 中级 / 高级）：初级\",\"用户的学习目标（用户学生设定的学习目标，比如理解流程、或者提高分析能力）：理解内科护理流程、提高病例分析能力\",\"用户的学习阶段（用户当前年级或学习阶段，比如大一，大二）：大一\",\"用户的学生专业（用户学生的专业方向，比如护理学，法律，土木工程）：护理学\",\"用户的最近的知识点（用户最近讨论过的关键知识点）：聊天机器人入门\",\"用户的弱点（用户学生较弱的知识点或技能）：难以理解代码, 不清楚自己的基础和专业, 认为AI课程难\",\"用户的交互风格（用户希望的交互风格，比如引导式提问、鼓励型、或者直接解释）：鼓励型带一点引导\"]')]\n",
      "文档引用: [ApplicationDocReference(index_id='3', title='第7周-提示词工程模块堂内练习内容', doc_id='file_9c8a13dbb29843fca396a7ef60e4b60f_12039021', doc_name='第7周-提示词工程模块堂内练习内容', doc_url=None, text='【文档名】:第7周-提示词工程模块堂内练习内容\\n【标题】:第7周-提示词工程模块堂内练习内容\\npipeline_name:AI基础课知识库\\n【正文】:第7周-提示词工程模块堂内练习内容\\n\\n课堂实时互动练习题:总结与挑战活动\\n\\n核心目标是帮助学生掌握五种常见的提示技巧,并通过实际动手操作提升其使用生成式AI的能力。为了增强互动性与实操性,课堂上将提供一个类似Playground的网页交互界面(WebUI),供学生实时输入提示词并观察模型输出结果。这种方式可以让学生直观地看到不同提示风格对AI生成内容的影响,从而更好地理解和应用提示工程的基本方法。\\n\\n练习内容概述\\n\\n在完成对五种核心提示技巧(结构化提示、少样本学习、思维链提示、ReAct提示和提示迭代)的讲解后,学生将在教师引导下进行一次课堂互动练习。每位学生将被要求:\\n\\n1.选择一种提示技巧;\\n\\n2.结合自己的专业背景,尝试撰写一个具体的提示词;\\n\\n3.在WebUI中输入提示词并查看AI的输出结果;\\n\\n4.对比预期效果,思考如何优化提示词以获得更理想的回应。\\n\\n示例引导机制\\n\\n为了降低初学者的理解巾槛,课堂会展示一个完整的提示词与输出结果的案例,但不会直接告诉学生该提示词的具体写法。学生需要根据提示词的大致描述与最终输出的效果,推测可能使用的提示策略,并尝试复现或改进这一提示词。\\n\\n这种\"结果导向\"的练习方式有助于学生从实际应用出发,理解提示词的设计逻辑,同时也能激发他们结合自身专业背景进行创新尝试的兴趣。\\n\\n教学支持工具\\n\\n我们将使用中文无代码平台(如通义千问、文心一言等)作为基础,搭建一个简洁易用的WebUI界面, 模拟Playground的功能。学生无需登录账号即可快速测试提示词,且所有数据均在课堂环境中本地处理,确保教学过程的安全与合规。\\n\\n核心教学理念\\n \\n·提示即对话:AI不是黑箱,而是一个可以通过语言引导的智能助手;\\n\\n·好提示=清晰+有结构+可迭代;\\n\\n·技术应用离不开专业背景的支持,只有结合学科知识,才能真正发挥AI的潜力;\\n\\n·无需编程基础,只要会\"说话\",就能用好AI。\\n \\n\\n', biz_id=None, images=None, page_number=None), ApplicationDocReference(index_id='4', title='第7周-提示词工程模块课件内容', doc_id='file_b732ae99b8874f6a893e5211bdd38b19_12039021', doc_name='第7周-提示词工程模块课件内容', doc_url=None, text='【文档名】:第7周-提示词工程模块课件内容\\n【标题】:第7周-提示词工程模块课件内容\\npipeline_name:AI基础课知识库\\n【正文】:第7周-提示词工程模块课件内容\\n\\nTopic 1:什么是提示工程(Prompt Engineering)\\n\\n第1页:封面页\\n\\n标题:提示工程(Prompt Engineering)入巾\\n\\n副标题:与AI高效对话的艺术\\n\\n脚本:欢迎大家来到第七周的课程的第一小节!今天我们来学习\"什么是提示工程\"。通过本节课,你会了解提示工程的基本概念、原理和实际应用。\\n\\n第2页:提示工程的定义\\n\\n标题:什么是提示工程?\\n\\n内容:\\n\\n·提示工程(Prompt Engineering) =与AI打交道的艺术\\n\\n·通过精心编写提示词,引导AI产生想要的回答\\n\\n·类比:阿拉丁神灯——愿望越清楚,结果越满意\\n\\n图片/风格建议:灯神与许愿的卡通插画\\n\\n脚本:大家可能会好奇:什么是提示工程?简单来说,提示工程就是与AI打交道的艺术。我们通过精心编写提示词,也就是给AI的指令或问题,来引导大型语言模型产生我们想要的回答。就像拥有一盏阿拉丁神灯,如果你的许愿含糊不清,灯神未必能满足你的期望;但如果描述得清楚具体,得到的结果就更接近心意。提示工程的作用正是在于教会我们如何清楚准确地向AI提问,从而获得高质量答案。\\n\\n第3页:AI如何\"理解\"我们的语言\\n\\n标题:AI如何\"理解\"我们的语言?\\n\\n内容:\\n\\n·当前AI(如ChatGPT、 Deepseek) 并不真正\"理解\"含义\\n \\n·AI通过概率预测生成回答\\n\\n·训练自海量文本,掌握词语和句子的统计模式\\n\\n·类比:手机输入法的联想功能\\n\\n图片/风格建议:AI大脑、概率曲线、手机输入法的联想气泡\\n\\n脚本:那么,AI是如何理解我们的语言的呢?这里需要强调:当前的AI(例如ChatGPT, Deepseek 等大语言模型)并不像人类那样真正\"理解\"含义,而更像是在做概率预测。模型阅读了海量文本,通过机器学习掌握了词语和句子的统计模式。当你向它提问时,它会将你的语言转换成内部的数学表示,然后根据训练中学到的模式预测下一步应该输出什么。这有点像我们手机输入法的联想功能——会根据已有的文字猜测你接下来要输入的词,只不过大型语言模型的\"联想\"能力强大得多。\\n\\n第4页:提示质量的重要性\\n\\n标题:为什么提示质量很重要?\\n\\n内容:\\n\\nAI只是\"猜\"出一个看起来像答案的回应\\n\\n·好的提示让模型预测更可靠\\n\\n·差的提示可能导致偏题或错误回答\\n\\n·结论:好的回答来自于好的提问\\n\\n图片/风格建议:对比\"模糊\"与\"清晰\"指令的图示\\n\\n脚本:因此,与其说AI理解了你的问题,不如说它猜出了一个看起来像答案的回应。正因为如此,我们输入的提示质量就格外重要:好的提示能让模型的预测更可靠,差的提示可能让模型产生偏题甚至错误的回答。换句话说,好的回答来自于好的提问。\\n\\n第5页:提示工程的意义\\n\\n标题:提示工程的意义\\n\\n主要内容:\\n\\n优化提问方式,提升AI输出质量\\n\\n入巾易,精通难\\n\\n需要技巧,才能让AI输出准确、有用的结果\\n \\n图片/风格建议:阶梯、目标靶心或\"入巾\"到\"精通\"的渐变图\\n\\n脚本:提示工程的意义在于:通过优化提问的方式,我们可以大大提升AI给出满意答案的概率。同学们可能觉得, 跟ChatGPT对话谁不会呀?随便问就行了。但实际上,提示工程是\"入内易,精通难\"。简单的提问人人都会,但要让AI输出准确、有用的结果,我们需要一些技巧。\\n\\n第6页:案例对比   -模糊提示vs.清晰提示\\n\\n标题:案例对比:模糊提示vs.清晰提示\\n\\n内容:\\n\\n| 模糊提示|清晰提示|\\n| ---|---|\\n|  |\"请写一篇约300字的短文,主题是人工智能在|\\n\\n\"写一篇文章。\"                        护理行业中的应用,语言生动且易于理解。请\\n\\n举一个护理工作中使用AI的具体案例。\"\\n\\n图片/风格建议:两份文章输出的对比(可用图标或缩略文本表示)\\n\\n脚本:举个案例对比来体会提示工程的重要性:比如我们想让AI写一篇文章。如果我们只是给出一个非常笼统的指令——\"写一篇文章。\"—AI可能无从下手,不知道我们想要什么主题、什么风格、多长的文章,结果往往不尽如人意。但是,如果我们换一种方式,提供一个清晰具体的提示,比如:\"请写一篇约300字的短文,主题是人工智能在护理行业中的应用,语言生动且易于理解。请举一个护理工作中使用AI的具体案例。\"这样一来,AI就能按照我们描述的清晰指令去生成内容,写出的文章就更符合我们的期望。这个例子中,我们把一个模糊的请求变得具体明确,AI输出的质量明显提高。这正是提示工程发挥作用的体现。\\n\\n第7页:总结与启发\\n\\n标题:总结\\n\\n主要内容(要点式):\\n\\n·提示工程=与AI高效沟通的桥梁\\n\\n·好的提问带来高质量回答\\n\\n·掌握提示工程,释放AI潜力\\n\\n图片/风格建议:桥梁、灯泡、AI与人类握手等象征合作的图像\\n \\n脚本:这个例子中,我们把一个模糊的请求变得具体明确,AI输出的质量明显提高。这正是提示工程发挥作用的体现。希望大家通过这个小节的学习,能够意识到:提示工程是与AI高效沟通的桥梁,好的提问带来高质量的回答。掌握提示工程,能让我们更好地释放AI的潜力。\\n\\n主题1的选择题\\n\\n你想让AI写一篇约300字、语言生动易懂、主题为\"人工智能在护理行业中的应用\"的短文,并举出一个具体案例。下面哪一个提示 (Prompt) 最符合提示工程的原则,最有可能一次就得到满意的答案?\\n\\nA.「写一篇文章。」\\n\\nB.「请写一篇文章,主题是护理。」\\n\\nC.「你是一名护理信息学专家。请写一篇约300字的短文,说明人工智能在护理行业中的应用,并举一个护理工作中使用AI的具体案例,语言生动、易于理解,分三段呈现。」\\n\\nD.「写300字,关于护理Al。」\\n\\n参考答案\\n\\nC\\n\\n选项反馈\\n\\n选项\\n\\nA\\n\\n| 反馈说明|\\n| ---|\\n| 过于笼统:没有任何主题、长度、风格或格式要求,属于\"含糊提问\"。模型不知道你想要什么内容或深度,极易跑题或生成与护理无关的文章。|\\n\\n缺乏关键细节:虽然给出主题\"护理\",但仍未\\n\\n说明篇幅、语言风格、是否需要举例等信息,\\n\\nB\\n\\n也未指定角色。结果可能篇幅不符或内容泛泛\\n\\n而谈。\\n\\nC                                  最佳提示:①指定角色(护理信息学专家)\\n\\n保证专业度;(②)日明确字数(约300字)和输\\n\\n出结构(分三段);③给出主题与案例要求;\\n\\n④要求语言生动易懂。充分满足\"清晰具体、\\n\\n提供上下文、  指定角色、  指明输出格式\"等提\\n \\n选项\\n\\nD\\n\\n| 反馈说明|\\n| ---|\\n| 示工程原则,因此最可能一次生成高质量答案。|\\n| 信息不完整:只给了字数和主题关键词,没有说明语言风格、是否举例或结构要求,且未说明模型身份。尽管比A/B稍好,但仍缺少足够上下文和格式指令,会导致结果质量不稳定。|\\n\\n7Topic 2: Prompt提示的结构基础\\n\\n第1页:封面页\\n\\n标题:基本提示结构:与AI高效对话的框架\\n\\n副标题:掌握结构化思维提升AI输出质量\\n\\n脚本:那么继续开始我们第七周的课程的第二小节!有了上一章节对提示工程的基本认识,我们接下来关注如何构建一个好的提示。\\n\\n第2页:构建高质量提示的三大支柱\\n\\n标题:构建高质量提示的三大支柱\\n\\n内容:\\n\\n·一个好的Prompt通常包含三个关键要素:\\n\\n角色(role):这一部分给模型设定身份或上下文\\n\\no指令(Instruction) :这个部分是核心提问-你具体想让AI做什么。\\n\\n格式要求(Format) :结构话想要的输出格式\\n\\n·这三者像\"三大支柱\",让提问更有针对性,更高效。\\n\\n图片/风格建议:三个色块/圆环/支柱形状,分别标注\"角色\"\"指令\"\"格式\",中间用线连接,形成支撑结构的视觉感然后链接在一起。Link the three together to output.\\n\\n脚本:那么我们如何来构建一个好的提示词呢?总的来说一个精心设计的提示词往往不只是随意的一句话,而是可能包含多个部分,共同为AI指明方向。一般来说,一个完整的Prompt提示可以拆分为几个关键要素,我们这里强调其中最常用的三部分:角色(Role)、指令(Instruction) 和格式要求(Format)。我们可以把这三个要素想象成提示词的\"三大支柱\",帮助我们的提问更加有的放矢。\\n \\n第3页:角色(role))一设定AI的身份\\n\\n标题:角色(Role) -) 一设定AI的身份\\n\\n内容:\\n\\n·1角色是给AI设定身份或语境,让回答更专业、贴合场景。\\n\\n·例子:\\n\\n\"你是一名律师,请解释合同法中的要点\"\\n\\n\"你是一名有经验的护士,请分析以下病例\"\\n\\n\"你现在是我的中文老师,请帮我..\"\\n\\n\"你是一位美食评论家\"\\n\\n图片/风格建议:\\n\\n·人物头像图标+职业服装元素(如法袍、护士帽)感\\n\\n·对话气泡突出\"角色\"设定\\n\\n脚本:首先是角色(Role) 。这一部分是给模型设定身份或上下文。为什么要这样做呢?因为大型语言模型是通用的,它什么都能聊一点,但如果我们希望得到专业且贴合情境的回答,最好告诉它应以什么身份来回答。举个例子,如果你在法律课上向AI提问,你可以先声明\"你是一名律师\"。这样模型在回答时,就会尝试用法律专业人士的口吻和知识去回答问题;又比如在护理场景下,你可以让模型\"作为一名有经验的护士\"来解答,它就会更加关注医疗护理方面的细节。设定角色实际上就是提供了回答的语境和视角。它可以是一种职业身份、专家类型,或者特定的语气风格。比如:\"你现在是我的中文老师,请帮我...\",模型听到这句,就会以中文老师那样循循善诱的方式回答。再比如:\"你是一位美食评论家\",那么回答可能就会多些美食品鉴的语言。通过角色,我们有效地收窄了模型回答的范围,让它更贴合我们需要的领域和风格。\\n\\n第4页:指令(Instruction)—明确你的需求\\n\\n标题:指令(Instruction) h)明确你的需求\\n\\n内容:\\n \\n·指令是你具体想让AI做什么,必须清晰、具体\\n\\n·使用清晰的动作动词,例如:解释、总结、列出、比较\\n\\n·聚焦于具体的概念或任务(与学科相关)\\n\\n·范围明确,避免模糊的表达\\n\\n·好指令的要素:\\n\\n0明确任务类型\\n\\n指出具体内容\\n\\n设定范围或限制\\n\\n·例子:\\n\\n0例子1:\\n\\n\"请总结以下文章的主要观点,并用两到三句话表达。\"\\n\\n■\"总结\"→明确动作动词(任务类型)\\n\\n■\"主要观点\"→具体内容\\n\\n■\"两到三句话\"→范围/格式要求\\n\\n0例子2:\\n\\n\"请找出病例描述中的关键症状,并解释可能的原因。\"\\n\\n■\"找出\"→明确动作动词\\n\\n■\"病例描述中的关键症状\"→具体内容\\n\\n■\"解释可能的原因\"→进一步任务/范围\\n\\n图片/风格建议:\\n\\n·任务清单图标、放大镜、重点标记符号\\n\\n例句用不同颜色高亮动词、内容、范围,并用箭头或气泡标出\\n\\n·右侧留白用于callout说明\\n\\n脚本:接下来是指令(Instruction),这是提示的核心部分——你具体想让AI做什么。指令一定要清晰、具体,用明确的动作动词,比如\"总结\"、\"解释\"、\"列出\"等。还要聚焦于一个具体的任务或概念,并设定好范围。回想我们之前讲的原则,含糊的请求往往得不到理想结果。所以在编写提示时,指令部分要直截了当。例如,你想让AI帮你总结一段文本,那么指令可以是:\"请总结以下这段文章的主要观点,并用两到三句话表述。\"这里\"总结主要观点\"就是任务,\"两到三句话表述\"则已经带了格式要求。我再举一个例子:假如我们在医疗场景下,有一段病历文本需要分析,指令可以这样写:\"请找出下面病例描述中的关键症状,并解释这些症状可能指向的潜在问题。\"这样的指令明确指出任务是提取症状并解释意义。总之,指令部分要让模型一眼就看明白你的具体需求是什么。可以想想,如果把这个任务交给人类同学,对方需要知道哪些信息?我们就尽量在指令里把这些说清楚。\\n \\n第5页:格式要求((Format)一规定答案的呈现方式\\n\\n标题:格式要求(Format)-)—规定答案的呈现方式\\n\\n内容:\\n\\n·不格式要求让AI输出更符合你的使用场景。\\n\\n·常见格式要求:\\n\\n希望答案以段落还是列表形式?((\"请用项目符号列出...\")\\n\\n0希望答案多长、多简洁?(\"每条不超过20字\"或\"回答控制在100字以内\")\\n\\no是否需要特定的语气或风格?(\"用幽默的语调回答\"或\"语言专业严谨\")\\n\\no是否要遵循某种模板?(\"按照时间-地点-人物三个方面来描述\")\\n\\n或者输出机器可读的格式, 比如JSON、XML表格等 (\"以JSON格式输出结果\")\\n\\n·例子:\\n\\n \"请按表格形式列出法律条款的要点,表头包括条例名称和主要内容。\"\\n\\n图片/风格建议:\\n\\n·列表、表格、对话气泡等图标\\n\\n·色块突出\"格式\"关键词\\n\\n脚本:第三部分是格式要求 (Format)。这一要素经常被忽视,但实际上非常重要。模型给出的答案如果结构混乱、不符合我们需要的格式,即使内容对了,可能还需要我们二次整理。所以在提示中提前说明希望的输出格式,可以省去很多麻烦。格式要求包括很多方面,比如:\\n \\n·希望答案以段落还是列表形式?(\"请用项目符号列出...\")\\n\\n·希望答案多长、多简洁?(\"每条不超过20字\"或\"回答控制在100字以内\")\\n\\n·是否需要特定的语气或风格?(\"用幽默的语调回答\"或\"语言专业严谨\")\\n\\n·是否要遵循某种模板?(\"按照时间-地点-人物三个方面来描述\")\\n\\n·或者输出机器可读的格式, 比如JSON、XML表格等(\"以JSON格式输出结果\")。\\n\\n这些格式提示能让AI更好地呈现它的答案,方便我们直接使用。举个例子,如果我们让AI帮忙整理一份法律条文清单,就可以在提示中加上:\"请按表格形式列出法律条款的要点,表头包括条例名称和主要内容。\"有了这样的格式指示,AI的回答就很可能已经是排好表格要点的形式,我们拿来就能做PPT或报告了。\\n\\n第6页:三要素综合示例\\n\\n标题:三要素综合示例\\n\\n内容:\\n\\n·角色:你是一名经验丰富的儿科护士\\n\\n·指令:请阅儿童病例描述并通俗易懂的语言累出三个护理要点。病例描述:5岁男童,发热39.2℃,咳嗽两天,食欲减退,精神尚可,听诊双肺有轻微罗音。\\n\\n·格式要求:用项目符号格式展示结果,每个要点不要超过20个字。\\n\\n·基于三要素的输出示例:\\n\\n检测体温变化,及时无力降温\\n\\n0确保患儿充分休息和水分摄入\\n\\n观察呼吸情况,如有异常及时叫医生\\n\\n图片/风格建议:\\n\\n·护士卡通形象,列表图标\\n\\n·三色分区突出三要素\\n\\n脚本:现在我们把角色、指令、格式这三要素综合一下,来看一个完整提示词示例,更直观地体会各部分如何配合。假设我们有一个护理专业的应用场景:我们想请AI阅\\n \\n读一个儿童病例并给出护理要点,而且我们希望回答以要点列表形式呈现。我们可以这样写提示:\\n\\n\"你是一名经验丰富的儿科护士,请阅儿童病例描述并通俗易懂的语言累出三个护理要点。病例描述:5岁男童,发热39.2°℃,咳嗽两天,食欲减退,精神尚可,听诊双肺有轻微罗音。请用项目符号格式展示结果,每个要点不超过20个字。\"\\n\\n这个提示可以拆解为:\\n\\n·角角色:\"你是一名经验丰富的儿科护士\"——-让模型以儿科护士的专业视角来思考问题;\\n\\n·指令:\"阅读病例描述并用通俗易懂的语言列出三个护理要点\"-明确告诉模型任务是提炼护理要点,语言要求通俗易懂,数量是三个要点;\\n\\n·格式要求:\"用项目符号格式展示结果,每个要点不超过20个字\"一—一规定了回答应该是bullet点形式, 而且对每点的长度做了限制。\\n\\n可以想见,有了这样的提示,模型会给予一个清晰的回答,:\\n\\n监测体温变化,及时物理降温\\n\\n确保患儿充分休息和水分摄入\\n\\n观察呼吸情况,如有异常及时就医\\n\\n这样的输出就是我们理想中包含三条护理要点的列表了。这例子里,我们把角色、指令、格式三要素都用上,确保了回答的专业性、准确性和易读性。\\n\\n小结一下:提示词的结构化能够提高我们提问的有效性。并不是每个场景下都需要把这些要素全部用上,但在设计提示时,心里可以过一遍:\"我有没有交代背景角色?任务说明清不清楚?需不需要指定格式?\"这样检查一遍,能让提示更加完善。\\n\\nTopic 2的选择题\\n\\n问题:\\n\\n以下哪一项最能体现\"格式要求(Format)\"在结构化提示中的作用?\\n\\nA.指定AI回答时要用律师的身份\\n\\nB.让AI用项目符号列出要点,每条不超过20字\\n\\nC.要求AI解释某个法律概念\\n\\nD.让AI用幽默的语气回答\\n\\n参考答案:\\n \\nB.让AI用项目符号列出要点,每条不超过20字\\n\\n选项反馈\\n\\n| 选项反馈说明这个选项属于\"角色(Role)\"的设定,即让AI以特定身份或视角来回答问题。角色设定可以A让回答更贴合专业领域,但它并没有规定答案的呈现形式,所以不属于\"格式要求\"正确!这就是\"格式要求(Format)\"的典型例子。你明确告诉AI答案要用项目符号(bullet points)来列出,而且每条要点的字数有具体B限制。这种要求可以帮助你直接获得结构清晰、方便使用的输出,减少后期整理的工作量。这个选项是\"指令(Instruction)\",即你在告诉AI需要完成什么具体任务,比如\"解释\"、\"总C结\"或\"分析\"。虽然指令很重要,但它没有涉及答案的具体呈现方式,所以不属于\"格式要求\"。这个选项涉及的是\"表达风格\"或\"语气\",有时可以作为格式要求的补充,但它本质上是对回D答语气的规定,而不是对答案结构或输出形式的要求。格式要求通常更关注答案是以列表、表格、段落等形式输出。|\\n| ---|\\n\\nTopic 3: Few-shot Learningg少样本提()第1页:封面页\\n\\n标题:少样本学习\\n\\n副标题:用实例让AI\"看懂\"你的需求\\n\\n脚本:那么继续开始我们第七周的课程的第三小节!上一章我们重点学习了一下提示工程的基础结构,那么这个小节我们延展的学一下提示工程的另一个技巧 一少样本提示(Few-shot learning) 用实例让AI\"看懂你的需求。\\n \\n第2页:什么是少样本学习\\n\\n标题:什么是少样本学习\\n\\n内容:\\n\\n·定义:少样本学习((Few-shot learning)是一种通过给人工智能提供少量你想要的示例来训练它的方法。\\n\\n·类比:像给新同学做示范,他就能模仿你的做法\\n\\n·1作用:让AI更准确地模仿你的思路和表达方式\\n\\n图片建议:\\n\\n·左侧为老师示范,右侧为学生模仿(卡通风格)\\n\\n·下箭头连接\"示例\"与\"AI输出\"\\n\\n脚本:少样本提示技巧。这个名字听起来有点学术,其实概念很直观:当我们想让AI按照某种特定的模式或风格回答时,可以在正式提问之前,先给它提供几个示例(样本)。模型通过这些示例就能\"明白\"我们想要的回答格式或风格,然后再根据我们给的新问题,沿着示例的路子生成答案。先说定义:Few-shot提示指的是, 在你的prompt中不仅包含最后的问题,还包括一系列范例问答或范例任务的输入输出。简单来说,就是先教后问:先举例子给AI看,然后让它仿照例子的方式回答你最后的问题。举个通俗的比喻:这有点像我们做功课时先看了两道例题的解答,再去解第三道类似的问题。有了前面的参考,第三道题往往更好上手。AI模型在提示中看到前面的示例后,也会在潜意识里学到:\"哦,原来遇到这种提问,该按照这种风格来回答。\"\\n\\n第3页:什么时候使用少样本学习?\\n\\n标题:什么时候使用少样本学习?\\n\\n内容:\\n\\n单靠文字提示效果不理想\\n\\n·需要特定格式或风格(如写诗,专业用语)\\n\\n·涉及复杂或专业判断的情况\\n\\n·希望AI能处理高级概念、做出细致区分,或遵循复杂的逻辑结构。\\n\\n图片建议:\\n\\n·对比图:zero-shot和few-shot输出的差异\\n \\n·格式、风格、专业、批量等关键词图标\\n\\n脚本:那么,什么时候我们需要使用少样本学习提示呢?一个典型场景是:当简单文字提示效果不理想时。简单文字提示就是不提供任何示例,直接发问。很多情况下零样本已经能得到不错的答案,但有时模型的回答风格、精准度不符合要求。这时少样本学习就能派上用场了。比如:\\n\\n·需要特定格式或风格:假设我们希望AI的回答遵循严格的格式,或者模仿某种语气。如果直接要求,模型可能拿捏不准。但如果给它一两个范例,它就会模仿范例格式输出。例如你要它写诗,用几首小诗做示例,再让它写新的,它更能对仗出类似风格。\\n\\n·1任务较复杂或专业:当问题涉及一些专业领域知识或特定解题过程时,提供示例可以让模型参考解题思路。尤其对于推理题,少样本学习示例可以包含解决问题的过程,这样模型在新问题上也会尝试类似的推理路径。\\n\\n·车输出需要一致性:比如你要让AI批量处理多条相似的任务(翻译句子、分类短语等),给一个例子翻译或分类,模型对后续类似输入就能保持一致的标准。\\n\\n第4页:少样本提示的结构\\n\\n标题:少样本提示的结构\\n\\n内容:\\n\\n·结构:\\n\\no一个明确的任务说明\\n\\n02-3组\"输入-输出\"示例\\n\\no你的新问题/输入\\n\\n·关键要素:\\n\\n使用2-3个示例(太多会干扰AI)\\n\\n输入/输出格式保持一致\\n\\n示例应准确展示你想要的模式\\n\\n0示例要具体、清晰\\n\\np最后给出明确的新任务指令\\n\\n图片建议:\\n \\n·三步流程图:任务→示例→新输入\\n\\n·箭头串联,突出\"先例后问\"\\n\\n脚本:少样本提示的结构通常是这样的:在最终要问的问题之前,列出若干示例,每个示例包含一个输入和对应的输出。然后再提出我们真正的问题/输入。模型会把前面的示例当作对话或任务的一部分,从而推断出回答的模式。\\n\\n第5页:简单领域案例\\n\\n标题:法律领域少样本提示例子演示\\n\\n内容:\\n\\n·任务:用正式,简明风格解释法律概念\\n\\n·例子1:\\n\\no问:简要解释什么事过失责任?\\n\\n0答案:过失责任是指因行为人疏忽大意或未尽合理注意义务而导致他人受到损害需承担的法律责任。例如司机未注意路况撞伤行人,就属于过失导致的侵权,需要承担相应的赔偿责任。\\n\\n·例子2:\\n\\no问:简要解释什么是合同违约?\\n\\n答案:合同违约是指一方当事人未按照合同约定履行义务所产生的法律后果。例如卖方未按时交货构成违约,需根据合同约定承担赔偿等违约责任。\\n\\n·你的问题(新问题):\\n\\no问:简要解释什么是知识产权侵权。\\n\\n答案(让AI模仿上面风格作答的结果):知识产权侵权是指未经权利人许可而使用其知识产权并造成损害的行为,需要承担相应的法律责任。例如未经作者同意擅自转载其作品并营利,就属于侵犯著作权的行为。\\n\\n·注意:few-shot 示例不宜过多\\n\\n图片建议:\\n\\n法律天平、问答框\\n\\n·颜色分区突出\"问-答\"结构\\n \\n脚本:我们来看一个具体案例,用few-shot提示展示其效果。假设我们有一个法律问答的任务,希望AI用比较正式、简明的风格来回答法律概念。零样本情况下,直接问法律问题,AI可能回答风格不统一或不够严谨。而通过提供示例,我们可以引导它。你们可以用30秒,看一下页面的这个例子。\\n\\n(等待30秒)\\n\\n好的,我们一起看一下这个例子。在这个提示中,我们提供了两个示例问答:\\n\\n·元示例1问\"过失责任\"是什么,答案里给出了定义并举了例子,语言比较正式且简洁;\\n\\n·示例2问\"合同违约\",答案同样给出定义再举例,格式和语气与示例1一致。\\n\\n接着我们提出真正想问的问题:\"知识产权侵权是什么?\"并让模型作答。由于有前面两个示例的指导,模型很可能按照类似的风格来回答。例如,模型可能生成:\\n\\n\"答:知识产权侵权是指未经权利人许可而使用其知识产权并造成损害的行为,需要承担相应的法律责任。例如未经作者同意擅自转载其作品并营利,就属于侵犯著作权的行为。\"\\n\\n可以看到,模型的回答风格和结构模仿了示例:先定义概念,再举例说明,语气正式且内容准确。通过few-shot,我们成功地让AI对齐到了我们想要的回答模式。如果没有这些示例,模型也许仍能答对概念,但可能不会这么有条理地给例子,或者用词上不够正式。\\n\\n需要注意的是,few-shot示例不宜过多,一般1到5个示例已经能明显影响输出,但如果给太多示例,提示会变长,占用模型的输入空间,而且可能让模型在细节上过度拟合示例。我们要挑代表性强的例子给模型看。\\n\\n主题3的选择题:\\n\\n问题:在以下哪种情况下,使用\"少样本提示示 (Few-shot Prompting) \"最能显著提升AI的输出效果?\\n\\nA.你需要AI快速回答一个事实性问题,如:\"中国的首都是哪里?\"\\n\\nB.你想让AI用特定格式写一份会议纪要,例如包括时间、地点、参与人和总结要点\\n\\nC.你希望AI生成一段随机的小说情节,没有具体风格或结构要求\\n\\nD.你要求AI翻译一段标准英文新闻句子成中文\\n \\n参考答案:\\n\\nB.你想让AI用特定格式写一份会议纪要,例如包括时间、地点、参与人和总结要点选项反馈:\\n\\n| 选项|反馈说明|\\n| ---|---|\\n|  |这个任务非常简单且标准化,通常使用零样本|\\n|  |提示(zero-shot prompting) 就能得到准确答案。不需要提供示例来引导模型输出格式或|\\n|  |风格。|\\n\\nA\\n\\n正确!这是一个非常适合使用少样本提示的场\\n\\n景。通过提供1-3个格式规范的会议纪要示\\n\\nB\\n\\n例,可以让AI明确了解你期望的输出结构和内\\n\\n容要素,从而生成更符合预期的回答。\\n\\n如果对输出没有具体格式或风格要求,那么提\\n\\n供示例可能反而会限制AI的创造力,或者导致\\n\\nC\\n\\n其偏离自由发挥的方向。这种情况下,零样本\\n\\n提示通常更适合。\\n\\n| 翻译属于高度结构化任务,尤其对于常见语言对(如英译中),AI已经训练得非常成熟。在|\\n| ---|\\n\\nD\\n\\n这种情况下,  即使不提供示例,也能获得高质\\n\\n量结果,因此few-shot提示并非必要。\\n\\nTopic 4: Chain-of-Thought提示示思维7提示)\\n\\n第1页:封面页\\n\\n标题:Chain-of-Thought提示(思维链提示)\\n\\n副标题:让AI像人一样\"链式思考\",逐步推理,提升复杂问题解答的可靠性\\n\\n脚本:本章节,我们来学习另一个提示工程的重要技术 ! Chain-of-Thought 提示,中文可以叫**\"思维链提示\"。这是提示工程中非常强大的一种技巧,顾名思义,它让模型像人一样链式地思考**。\\n\\n第2页:什么是思维链提示法?\\n \\n标题:什么是思维链提示法?\\n\\n内容:\\n\\n·定义:要求AI在给出最终答案之前,逐步展示其推理过程。\\n\\n·类比:人做复杂题会先列公式、再算步骤、最后得答案\\n\\n图片/风格建议:\\n\\n·\"问题→步骤1→步骤2→结论\"流程图\\n\\n·人和AI思考泡泡对比\\n\\n脚本:那么什么是链式思维呢?简单来说,就是把一个复杂问题拆解成一连串较小的推理步骤,一步一步得出结论。通常,人类在解决复杂问题时会在脑海中逐步推演,比如做数学题会先列公式,再算步骤,再得答案。Chain-of-Thought提示就是鼓励Al也显式地走这样的过程,而不是直接蹦出答案。\\n\\n第3页:思维链提示是怎么工作的?\\n\\n标题:思维链提示是怎么工作的?\\n\\n内容:\\n\\n·要求AI\"逐步思考\"问题\\n\\nAI将复杂任务拆解为逻辑步骤\\n\\n在每一步中展示其推理过程\\n\\n·十形成一条\"思维链\",最后一环才是结果\\n\\n图片/风格建议:\\n\\n·链条/阶梯式流程图,每环代表一个推理步骤\\n\\n·\"分步\"关键词高亮\\n\\n脚本:我们在这里定义一下:在提示中使用Chain-of-Thought,就是让模型逐步推理再回答。用最简单的例子来说,我们可以通过在提示里加入诸如\"请分步骤思考\"或者\"让我们一步一步推理这个问题\"的指示,来触发模型输出中间推理步骤。这些中间步骤就像是一条\"思维链\",最后一环才是结果。另一种方法可以使用我们上一个小节学到的关于少样本提示的技巧,我们可以在少样本提示示例里直接展示带推理过程的解答,让模型学会模仿。在这些示例中,每个问题的答案不是直接给结果,而是先写出推理过程,再给出结论。模型看到这样的范例,自然在新问题上也会按步骤列出思路。\\n \\n第4页:思维链的优势\\n\\n标题:思维链的优势\\n\\n内容:\\n\\n·复杂推理中的错误\\n\\n·让AI的逻辑清晰可见、便于验证\\n\\n·每一步都简单明确,结果更准确\\n\\n·帮助你理解答案背后的\"原因\"\\n\\n·提高AI的可解释性和可靠性\\n\\n·特别适用于需要批判性思维的专业领域\\n\\n图片/风格建议:\\n\\n·放大镜+链条,突出\"可检查、可解释\"\\n\\n·\"错误\"与\"正确\"对比图\\n\\n脚本:为什么CoT有用呢?因为让模型把思考过程显式写出来,可以减少它犯逻辑错误的概率。当问题复杂时,如果不鼓励逐步推理,模型有时会图省事儿直接给一个可能的答案,但那答案可能错或者缺乏依据。而如果我们要求它一步步推导,每一步都比较简单明确,最后得到的结果往往更准确。而且,我们作为人类读者也能看到它的推理过程,便于理解回答从何而来。特别是在需要批判思维专业领域。\\n\\n第5页:案例对比\\n\\n标题:案例对比\\n\\n内容:\\n\\n·普通提问(无思维链提示)\\n\\no问题:\"患者发烧、咳嗽,呼吸急促,请问可能的诊断是什么?\"\\n\\n回答:\"可能是肺炎\"\\n \\n·思维链提示:\\n\\n·问题:\"患者发烧、咳嗽,呼吸急促,请一步一步分析患者症状并给出可能的诊断?\"\\n\\n·回答:\"第一,患者发烧且咳嗽,说明存在感染的迹象,多见于呼吸道感染。第二,出现呼吸急促,提示下呼吸道可能受累,比如肺部感染。结合以上症状,最可能的诊断是肺炎。此外,也需考虑支气管炎,但高烧更倾向于肺炎。综上所述,最可能的是肺炎。\"\\n\\n图片/风格建议:\\n\\n·左右分栏:左为\"无CoT\",右为\"有CoT\"\\n\\n·医学图标+推理链图\\n\\n脚本:让我们通过案例对比来感受一下\"思维链提示\"的效果。考虑一个稍微复杂的问题场景,比如一个医学小诊断:问题:\"患者发烧、咳嗽,呼吸急促,请问可能的诊断是什么?\"没有使用思维链提示时,模型也许会直接给出一个简短回答,比如:\"可能是肺炎。\"这个回答听上去有道理,但我们不知道它如何得出这个结论,也不确定它是否考虑了所有症状。万一有其他可能,比如支气管炎、哮喘等,没有推理过程我们无法判断模型是不是凭直觉\"猜\"的。\\n\\n现在我们应用思维链提示来提问,同样的问题但加上指引:\"请一步一步分析患者症状并给出可能的诊断。\"这相当于明确要求模型列出推理过程。模型这次的回答可能会像这样展开:\"第一,患者发烧且咳嗽,说明存在感染的迹象,多见于呼吸道感染。第二,出现呼吸急促,提示下呼吸道可能受累,比如肺部感染。结合以上症状,最可能的诊断是肺炎。此外,也需考虑支气管炎,但高烧更倾向于肺炎。综上所述,最可能的是肺炎。\"\\n\\n对比两种回答,可以明显看出:使用了思维链提示后,模型给出了逐步推理的过程。它先考虑每个症状分别意味着什么,然后综合推理,最后才得出\"肺炎\"这个结论。这样的回答不仅更准确可信(因为我们看到了推理链条),也更有教学意义(让提问者明白了为什么会是这个诊断)。而直接回答\"可能是肺炎\"的版本虽然简洁,但缺乏依据支撑。如果当时正确答案不是肺炎,模型可能就误导了我们;而有了推理步骤,我们至少知道模型考虑过什么,可以发现如果它中间哪个推理不对。这个案例说明,在复杂问题上,思维链提示往往能提升AI解题的可靠性。\\n\\n第6页:思维链适用场景\\n\\n标题:思维链适用场景\\n \\n内容:\\n\\n·多步骤推理任务:\\n\\n0数学题(分布计算)\\n\\n逻辑推理,谜题\\n\\n医学诊断,法律分析\\n\\n·只要设计复杂思考,思维链都值得一试\\n\\n图片/风格建议:\\n\\n·不同行业图标:数学、法律、医学等\\n\\n阶梯式流程或环形流程图\\n\\n脚本:思维链技巧特别适用于多步骤推理场景。数学问题是经典例子:比如一道数学应用题,有多步计算,如果直接让模型回答,它可能一下子给错答案;但如果让它先列出计算过程,就像我们手算分步写草稿纸那样,最后答案往往正确率更高。再如逻辑推理题、谜语等等,需要考虑多个条件约束的题目,思维链也能帮助模型逐条理清思路。此外,在医学诊断、法律分析等需要综合分析的领域,这种逐步推理的方式也十分有用——就像刚才医疗案例中那样,或者在法律分析中逐条检查法条和事实再下结论。可以说,凡是涉及复杂思考的问题,思维链提示都是值得一试的方法。\\n\\ntopic 4的选择题:\\n\\n问题:以下哪种场景最适合使用Chain-of-Thought(思维链)提示?\\n\\nA.让AI直接回答\"中国的首都是哪个城市?\"\\n\\nB.让AI写一首关于春天的诗\\n\\nC.让AI分析患者发烧、咳嗽、呼吸急促的可能病因,并给出诊断依据\\n\\nD.让AI将100条用户评论分类为\"好评\"或\"差评\"\\n\\n参考答案:\\n\\nC.让AI分析患者发烧、咳嗽、呼吸急促的可能病因,并给出诊断依据\\n \\n选项反馈:\\n\\n选项\\n\\nA\\n\\nB\\n\\n| 反馈说明|\\n| ---|\\n| 这是一个简单的事实性问题,不需要多步推理。AI可以直接给出答案(北京),使用思维链提示反而冗余。|\\n| 诗歌创作属于创意性任务,需要自由发挥而非逻辑推理。思维链提示更适合需要结构化分析|\\n\\n的场景。\\n\\n正确!医学诊断需要综合症状、排除可能性并\\n\\n逐步推理,这正是思维链提示的典型应用场\\n\\nC                                   景。通过分步骤分析症状(如发热→感染可\\n\\n能,咳嗽→呼吸道问题,呼吸急促→肺部受\\n\\n累),AI的结论会更可靠且可验证。\\n\\nD\\n\\n| 分类任务通常不需要复杂推理,直接使用指令(如\"请分类以下评论\")或简单示例即可。思维链提示在此场景中价值有限。|\\n| ---|\\n\\nTopic 5:提示迭代(Iterative Prompting)\\n\\n第1页:封面页\\n\\n标题:提示迭代(Iterative Prompting)\\n\\n副标题:用\"试错-优化-再试\"的循环,打磨出满意的AI回答\\n\\n脚本:通过前几个章节的学习,现在你已经掌握了,提示词工程的基础和几个重要的技巧,接下来,本章节我们来讲一个在提示工程中非常实用且务必掌握的技巧的一个方法,提示迭代。\\n\\n第2页:什么是提示迭代?\\n\\n标题:什么是提示迭代?\\n\\n内容:\\n\\n·很少有人能第一次就写出完美提示\\n \\n·提示迭代=把和AI的交互看作循环:每次给出提示→AI回答→你评估→有针对性地修改提示→再问\\n\\n·这个过程像写文章反复润色,提示词也可以灵活调整\\n\\n·为什么迭代很重要:\\n\\no把\"好的提示\"变成\"优秀的提示\"\\n\\n0长期来看,通过更优结果节省时间\\n\\n0教你理解AI是如何解读语言的\\n\\n0是专业使用AI的必备技能\\n\\n帮助你建立与AI沟通的专业能力\\n\\n图片/风格建议:\\n\\n·\"编辑-反馈-再编辑\"循环流程图\\n\\n·书稿-红笔修改-定稿的视觉元素\\n\\n脚本:其实在前面的内容中,我们已经多次暗示过这一点:很少有谁能第一次就写出完美的提示,无论是专家还是新手,都需要一个不断试验-改进的过程。所以提示迭代讲的就是如何逐步打磨你的提示,直到AI给出让你满意的答案。提示迭代就是指你不要指望一杆进洞,而是把和AI的交互看作一个循环过程。每一轮你给出提示,模型给你一个回答,你评估一下这个回答哪儿好哪儿不好,然后有针对性地修改提示再问一遍。经过几轮下来,AI的回答通常会有明显改进,更接近你想要的。这种逐步优化提示的过程,就是提示迭代。它强调一个理念:Prompt不是写下就定死的,可以灵活调整。就像写文章会多次修改润色一样,写提示词也应该动态优化。\\n\\n第3页:提示迭代的流程\\n\\n标题:提示迭代的流程\\n\\n内容:\\n\\n·初始提示:草拟第一版,提交模型\\n\\n·不模型响应:AI给出答案\\n\\n·用户评估:对比预期,找出不满意的地方\\n\\n·修改提示:有针对性地补充、澄清、优化\\n \\n·再次询问:提交新提示,看效果\\n\\n·重复评估-修改-再询问,直到满意为止\\n\\n图片/风格建议:\\n\\n·用流程图或螺旋图可视化\\n\\n·每个步骤用不同颜色区分,箭头连接\\n\\n脚本:我们快速的看一下提示迭代的基础流程。这个流程看似平淡无奇,其实几乎每个用好AI的人都会在背后做这样的循环。首轮提示就好比你和AI交个底,如果它答偏了,你就再拉回来。通过迭代,我们可以逐渐逼近理想答案,而不是一下子全指望首次就完美。模型有时就像个按你要求作画的画家,你不断告诉他\"这里颜色深一点,那边线条细一点\",几次来回画作就精致了。\\n\\n第4页:为什么提示迭代很重要?\\n\\n标题:为什么提示迭代很重要?\\n\\n内容:\\n\\n·语言模型无法读心,第一次很难覆盖所有需求\\n\\n·通过迭代可以不断补充遗漏、纠正误解、优化表达\\n\\n·每次反馈都是\"调教\"AI,最终答案质量远高于初版\\n\\n就像指导画家:不断微调,作品越来越接近理想\\n\\n图片/风格建议:\\n\\n·\"画家-多次修改-成品画\"对比\\n\\n·\"对话气泡-反馈-再对话\"流程\\n\\n脚本:为什么提示迭代很重要?因为语言模型再强大,也无法读心。第一次你可能没想到要说明某个要求,而AI不知道却不给,你一看\"哦我漏说了这点\",下次补上,结果就更好了。或者模型第一次理解错了你的意思,给了偏差的答复,那么你下次可以直接在提示里纠正:\"上次你提到X,其实我需要的是Y,请重新..\"。另外,有时候模型回答暴露出它的信息盲区,比如提到了某错误细节—那下一轮我们就可以在提示中加入正确信息,或者干脆提示它避免某方面输出。总之,通过迭代,我们把模型朝着正确方向一步步引导,就像调教学生一样,不断纠错、补充,最终答案质量会远远好于一开始的水平。\\n \\n第5页:实际案例\\n\\n标题:实际案例-法律概念解释\\n\\n内容:\\n\\n·初始提示:\"解释一下法律中的过失和故意的区别。\"\\n\\nAI回答:过失是指行为人应当预见但因疏忽大意没有预见以致发生有害结果的心理态度,故意是行为人明知自己的行为会发生危害结果并且希望或放任这种结果发生的心理态度。两者区别在于主观心理状态不同。\\n\\n·第一次迭代:\"请用简单易懂的语言解释,并分别举一个日常例子。\"\\n\\nAI回答:在法律上,过失指的是一个人本来应该预见到自己的行为可能会造成不好的后果,但因为没注意或大意,没有预见,结果把坏事干了。简单说就是\\'不是故意但因为疏忽犯了错。比如:小张开车时在玩手机,没有注意红灯撞到了人。这就是过失造成的事故,因为他本来应该小心驾驶却疏忽了。而故意指的是一个人明明知道自己的行为会产生不好的后果,而且就是想要这么做或放任它发生。也就是说他是有意识地去做坏事。比如:小李对邻居不满,故意把垃圾倒在邻居家巾口,想让邻居难堪。这种就是故意的行为。两者区别在于:过失是\\'不小心\\'导致的,而故意是\\'有意\\'为之。\\n\\n·第二次迭代:\"最后请用一两句话总结两者区别要点。\"\\n\\nAI回答:总之,过失是不小心犯错,故意是有意犯错,这就是两者的根本区别。\\n\\n图片/风格建议:\\n\\n·三步对比卡片:初稿-改进-最终版\\n\\n·法律天平/对话气泡\\n\\n脚本:我们来看一个实际案例,感受提示迭代带来的变化。想象一个场景:一位法律专业的同学在自学,需要AI解释一个法律概念,比如\"过失\"和\"故意\"的区别,并举例说明。但这位同学没有AI提示经验,初始提示可能就写了:\"解释一下法律中的过失和故意的区别。\"这样的提示不算差,但是比较笼统。模型第一次的回答也许是这样的:\"过失是指行为人应当预见但因疏忽大意没有预见以致发生有害结果的心理态度;故意是行为人明知自己的行为会发生危害结果并且希望或放任这种结果发生的心理态度。两者区别在于主观心理状态不同。\"\\n \\n模型给的是法律教科书式定义,问题在于:语言生涩,普通人可能难以马上理解,而且它没有举例子。提问的同学一看,觉得太学术化了,不够通俗。那么他开始评估:需要回答更通俗易懂、加上例子。于是他修改提示,第二版提示也许这样:\\n\\n\"请用简单易懂的语言解释法律中的过失和故意的区别,并分别举一个日常生活中的例子来说明。\"\\n\\n模型收到这新的明确要求,第二次回答可能就好了很多:\\n\\n\"在法律上,过失指的是一个人本来应该预见到自己的行为可能会造成不好的后果,但因为没注意或大意,没有预见,结果把坏事干了。简单说就是\\'不是故意但因为疏忽犯了错\\'。比如:小张开车时在玩手机,没有注意红灯撞到了人。这就是过失造成的事故,因为他本来应该小心驾驶却疏忽了。\\n\\n而\\n\\n故意指的是一个人明明知道自己的行为会产生不好的后果,而且就是想要这么做或放任它发生。也就是说他是有意识地去做坏事。比如:小李对邻居不满,故意把垃圾倒在邻居家巾口,想让邻居难堪。这种就是故意的行为。两者区别在于:过失是\\'不小心\\'导致的,而故意是\\'有意\\'为之。\"\\n\\n看看这次的回答,是不是清楚多了?定义用大白话说出来,还有生活例子帮助理解。同学觉得基本满意。不过也许还有一点可以更好:答案有点长,他想要一个要点总结。那么他可以再迭代一次,第三版提示加上:\"最后请用一两句话总结两者的区别要点。\"这样模型会在上述回答末尾再补一句总结:\"总之,过失是不小心犯错,故意是有意犯错,这就是两者的根本区别。\"\\n\\n经过这一连串迭代,这位同学最终拿到了一个通俗易懂、信息完整的答案,远胜于初版的生涩定义。这就是提示迭代带来的收益。从初始到最终,提示变了三次,模型的答案品质一步步提升。\\n\\n通过这个案例可以体会:迭代的每一步都有明确目标(第1次让语言通俗+加例子,第2次再加总结要点),我们针对性调整提示,就像调参一样在优化输出。这要求我们在评估模型回答时,要学会发现问题所在,然后想:\"我能在提示里加入什么来解决这个问题?\"这实际上是一种与AI协作的思维:模型给你草稿,你指导模型修改,反复交互,直到得到满意作品。\\n\\n总而言之:别怕多问几次!把和AI交流当成一个渐进过程,善用每次反馈去完善下一次提问。真正熟练的提问者,绝不是第一次就问得十全十美,而是懂得不断逼近完美答案的人。\\n\\ntopic 5的选择题:\\n \\n问题:在使用AI写作或问答时,为什么\"提示迭代(Iterative Prompting)\"是一种非常重要的技巧?\\n\\nA.因为AI每次的回答都是完全随机的,必须多试几次才有可能碰到好答案\\n\\nB.因为通过多轮修改和反馈,可以逐步优化提示,让AI输出更接近你的真实需求\\n\\nC.因为AI只能理解非常简单的指令,复杂任务无法完成\\n\\nD.因为每次修改提示都会让AI忘记之前的内容\\n\\n参考答案:\\n\\nB.因为通过多轮修改和反馈,可以逐步优化提示,让AI输出更接近你的真实需求\\n\\nB\\n\\n| 选项|反馈说明|\\n| ---|---|\\n| A|AI的回答并不是完全随机的,而是根据你的提示和上下文生成的。多次尝试的意义在于优化提示,而不是\"碰运气\"|\\n|  |正确!提示迭代的核心就是通过反复调整和反馈,让AI的回答越来越符合你的要求。这是高效使用AI的关键方法。|\\n|  |AI可以完成复杂任务,只要你的提示足够清晰具体。迭代的作用是让复杂任务的提示越来越完善.|\\n|  |实际上,每次你修改提示,AI会根据新提示重新生成答案。迭代的价值在于你能不断补充和调整需求,而不是让AI\"遗忘\"|\\n\\nC\\n\\nD\\n \\n\\n', biz_id=None, images=None, page_number=None)]\n"
     ]
    }
   ],
   "source": [
    "question = \"这节课有什么内容\"\n",
    "result, session_id = chat_with_ai(question)\n",
    "\n",
    "if result:\n",
    "    print(\"AI回复:\", result['text'])\n",
    "    print(\"会话ID:\", result['session_id'])\n",
    "    print(\"请求ID:\", result['request_id'])\n",
    "    print(\"使用模型:\", result['model'])\n",
    "    print(\"输入token数:\", result['input_tokens'])\n",
    "    print(\"输出token数:\", result['output_tokens'])\n",
    "    print(\"完成原因:\", result['finish_reason'])\n",
    "    print(\"思考过程:\", result['thoughts'])  # 可能是 None\n",
    "    print(\"文档引用:\", result['doc_references'])  # 可能是 None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
